"""Decision Data Collector - DeepSeekè®­ç»ƒæ•°æ®æ”¶é›†å™¨"""

from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import json
import logging

logger = logging.getLogger(__name__)


class DecisionDataCollector:
    """
    å†³ç­–æ•°æ®æ”¶é›†å™¨
    
    èŒè´£ï¼š
    1. ä»PostgreSQLæ”¶é›†å†å²å†³ç­–æ•°æ®
    2. ä»Redisæå–å¸‚åœºå¿«ç…§
    3. ä»Qdrantè·å–å‘é‡åŒ–ç‰¹å¾
    4. æ ‡æ³¨å†³ç­–ç»“æœï¼ˆç›ˆåˆ©/äºæŸ/å‡†ç¡®åº¦ï¼‰
    5. ç”Ÿæˆè®­ç»ƒæ•°æ®é›†
    
    æ•°æ®æ ¼å¼ï¼š
    {
        "input": {
            "prompt": "å®Œæ•´çš„å†³ç­–Prompt",
            "market_data": {...},
            "intelligence_report": {...},
            "memory_context": {...}
        },
        "output": {
            "decision": {...},
            "expected_action": "...",
            "expected_confidence": 0.0
        },
        "result": {
            "actual_outcome": "success/failure",
            "pnl": 0.0,
            "duration_hours": 0.0,
            "accuracy_score": 0.0
        }
    }
    """
    
    def __init__(
        self,
        redis_client,
        db_session,
        qdrant_client=None
    ):
        """
        åˆå§‹åŒ–æ•°æ®æ”¶é›†å™¨
        
        Args:
            redis_client: Rediså®¢æˆ·ç«¯
            db_session: æ•°æ®åº“ä¼šè¯
            qdrant_client: Qdrantå®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
        """
        self.redis = redis_client
        self.db = db_session
        self.qdrant = qdrant_client
        
        logger.info("âœ… å†³ç­–æ•°æ®æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def collect_training_data(
        self,
        start_date: datetime,
        end_date: datetime,
        min_samples: int = 100,
        only_completed: bool = True
    ) -> List[Dict[str, Any]]:
        """
        æ”¶é›†è®­ç»ƒæ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            min_samples: æœ€å°æ ·æœ¬æ•°
            only_completed: åªæ”¶é›†å·²å®Œæˆçš„äº¤æ˜“
        
        Returns:
            è®­ç»ƒæ ·æœ¬åˆ—è¡¨
        """
        try:
            logger.info(
                f"ğŸ“¦ å¼€å§‹æ”¶é›†è®­ç»ƒæ•°æ®: "
                f"{start_date.date()} åˆ° {end_date.date()}, "
                f"ç›®æ ‡æ ·æœ¬æ•° >= {min_samples}"
            )
            
            # 1. ä»æ•°æ®åº“è·å–å†³ç­–è®°å½•
            decisions = await self._fetch_decisions_from_db(
                start_date, end_date, only_completed
            )
            
            logger.info(f"âœ“ ä»æ•°æ®åº“è·å– {len(decisions)} æ¡å†³ç­–è®°å½•")
            
            # 2. ä¸ºæ¯æ¡å†³ç­–æ”¶é›†å®Œæ•´æ•°æ®
            training_samples = []
            for decision in decisions:
                sample = await self._build_training_sample(decision)
                if sample:
                    training_samples.append(sample)
            
            logger.info(f"âœ“ æˆåŠŸæ„å»º {len(training_samples)} ä¸ªè®­ç»ƒæ ·æœ¬")
            
            # 3. æ•°æ®è´¨é‡æ£€æŸ¥
            valid_samples = self._validate_samples(training_samples)
            
            logger.info(f"âœ“ è´¨é‡æ£€æŸ¥åå‰©ä½™ {len(valid_samples)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
            
            # 4. æ£€æŸ¥æ˜¯å¦æ»¡è¶³æœ€å°æ ·æœ¬æ•°
            if len(valid_samples) < min_samples:
                logger.warning(
                    f"âš ï¸ æ ·æœ¬æ•°ä¸è¶³: {len(valid_samples)} < {min_samples}, "
                    f"å»ºè®®æ‰©å¤§æ—¶é—´èŒƒå›´æˆ–é™ä½è´¨é‡è¦æ±‚"
                )
            
            return valid_samples
            
        except Exception as e:
            logger.error(f"âŒ æ”¶é›†è®­ç»ƒæ•°æ®å¤±è´¥: {e}", exc_info=True)
            return []
    
    async def _fetch_decisions_from_db(
        self,
        start_date: datetime,
        end_date: datetime,
        only_completed: bool
    ) -> List[Dict[str, Any]]:
        """ä»æ•°æ®åº“è·å–å†³ç­–"""
        try:
            query = f"""
            SELECT 
                d.id,
                d.timestamp,
                d.symbol,
                d.market_data,
                d.decision,
                d.executed,
                d.reject_reason,
                d.model_name,
                t.id as trade_id,
                t.pnl,
                t.closed_at,
                t.status as trade_status
            FROM ai_decisions d
            LEFT JOIN trades t ON t.decision_id = d.id
            WHERE d.timestamp >= '{start_date.isoformat()}'
              AND d.timestamp <= '{end_date.isoformat()}'
            """
            
            if only_completed:
                query += " AND t.status = 'closed'"
            
            query += " ORDER BY d.timestamp DESC"
            
            result = await self.db.execute(query)
            rows = result.fetchall()
            
            decisions = []
            for row in rows:
                decisions.append({
                    "decision_id": row[0],
                    "timestamp": row[1],
                    "symbol": row[2],
                    "market_data": row[3],  # JSON
                    "decision": row[4],  # JSON
                    "executed": row[5],
                    "reject_reason": row[6],
                    "model_name": row[7],
                    "trade_id": row[8],
                    "pnl": float(row[9]) if row[9] else None,
                    "closed_at": row[10],
                    "trade_status": row[11]
                })
            
            return decisions
            
        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“è·å–å†³ç­–å¤±è´¥: {e}")
            return []
    
    async def _build_training_sample(
        self,
        decision: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """æ„å»ºå•ä¸ªè®­ç»ƒæ ·æœ¬"""
        try:
            decision_id = decision["decision_id"]
            
            # æ„å»ºè¾“å…¥éƒ¨åˆ†
            input_data = {
                "prompt": await self._reconstruct_prompt(decision),
                "market_data": decision["market_data"],
                "intelligence_report": await self._get_intelligence_context(decision),
                "memory_context": await self._get_memory_context(decision)
            }
            
            # æ„å»ºè¾“å‡ºéƒ¨åˆ†
            output_data = {
                "decision": decision["decision"],
                "expected_action": decision["decision"].get("action", "hold"),
                "expected_confidence": decision["decision"].get("confidence", 0.0)
            }
            
            # æ„å»ºç»“æœéƒ¨åˆ†
            result_data = self._build_result_data(decision)
            
            sample = {
                "sample_id": f"train_{decision_id}",
                "timestamp": decision["timestamp"].isoformat(),
                "input": input_data,
                "output": output_data,
                "result": result_data,
                "metadata": {
                    "symbol": decision["symbol"],
                    "model_name": decision["model_name"],
                    "executed": decision["executed"]
                }
            }
            
            return sample
            
        except Exception as e:
            logger.error(f"æ„å»ºè®­ç»ƒæ ·æœ¬å¤±è´¥ (decision_id={decision.get('decision_id')}): {e}")
            return None
    
    async def _reconstruct_prompt(self, decision: Dict[str, Any]) -> str:
        """é‡æ„å†³ç­–æ—¶çš„Prompt"""
        # ç®€åŒ–ç‰ˆï¼šå®é™…åº”è¯¥ä»æ—¥å¿—æˆ–è®°å½•ä¸­æ¢å¤å®Œæ•´Prompt
        market_data = decision["market_data"]
        
        prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“AIã€‚

ã€å¸‚åœºæ•°æ®ã€‘
å¸ç§: {decision['symbol']}
ä»·æ ¼: ${market_data.get('price', 'N/A')}
24hæ¶¨è·Œ: {market_data.get('change_24h', 'N/A')}

ã€ä»»åŠ¡ã€‘
è¯·åŸºäºä»¥ä¸Šä¿¡æ¯åšå‡ºäº¤æ˜“å†³ç­–ï¼Œè¿”å›JSONæ ¼å¼ã€‚

æ³¨ï¼šè¿™æ˜¯è®­ç»ƒæ•°æ®é‡æ„çš„ç®€åŒ–Promptï¼Œå®é™…åº”è¯¥åŒ…å«å®Œæ•´çš„çº¦æŸã€æƒé™ã€è®°å¿†ç­‰ä¿¡æ¯ã€‚
"""
        return prompt
    
    async def _get_intelligence_context(
        self,
        decision: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """è·å–æƒ…æŠ¥ä¸Šä¸‹æ–‡"""
        # TODO: ä»Redisè·å–å½“æ—¶çš„æƒ…æŠ¥æŠ¥å‘Š
        return None
    
    async def _get_memory_context(
        self,
        decision: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """è·å–è®°å¿†ä¸Šä¸‹æ–‡"""
        # TODO: ä»Qdrantè·å–å½“æ—¶çš„è®°å¿†å‘é‡
        return None
    
    def _build_result_data(self, decision: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºç»“æœæ•°æ®"""
        pnl = decision.get("pnl")
        closed_at = decision.get("closed_at")
        timestamp = decision.get("timestamp")
        
        # è®¡ç®—æŒç»­æ—¶é—´
        duration_hours = 0.0
        if closed_at and timestamp:
            duration = closed_at - timestamp
            duration_hours = duration.total_seconds() / 3600
        
        # åˆ¤æ–­ç»“æœ
        actual_outcome = "unknown"
        accuracy_score = 0.5
        
        if pnl is not None:
            if pnl > 0:
                actual_outcome = "success"
                accuracy_score = min(1.0, 0.5 + (pnl / 100))  # ç®€åŒ–è¯„åˆ†
            elif pnl < 0:
                actual_outcome = "failure"
                accuracy_score = max(0.0, 0.5 - (abs(pnl) / 100))
            else:
                actual_outcome = "neutral"
                accuracy_score = 0.5
        
        return {
            "actual_outcome": actual_outcome,
            "pnl": pnl if pnl is not None else 0.0,
            "duration_hours": duration_hours,
            "accuracy_score": accuracy_score
        }
    
    def _validate_samples(
        self,
        samples: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """éªŒè¯æ ·æœ¬è´¨é‡"""
        valid_samples = []
        
        for sample in samples:
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            if not sample.get("input") or not sample.get("output"):
                continue
            
            # æ£€æŸ¥ç»“æœ
            result = sample.get("result", {})
            if result.get("actual_outcome") == "unknown":
                continue  # è·³è¿‡æœªçŸ¥ç»“æœçš„æ ·æœ¬
            
            # æ£€æŸ¥Prompté•¿åº¦
            prompt = sample["input"].get("prompt", "")
            if len(prompt) < 50:  # Promptå¤ªçŸ­
                continue
            
            valid_samples.append(sample)
        
        return valid_samples
    
    async def export_to_jsonl(
        self,
        samples: List[Dict[str, Any]],
        output_path: str
    ) -> bool:
        """
        å¯¼å‡ºä¸ºJSONLæ ¼å¼ï¼ˆè®­ç»ƒæ•°æ®æ ‡å‡†æ ¼å¼ï¼‰
        
        Args:
            samples: è®­ç»ƒæ ·æœ¬åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            æ˜¯å¦å¯¼å‡ºæˆåŠŸ
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                for sample in samples:
                    # è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
                    training_item = {
                        "messages": [
                            {
                                "role": "system",
                                "content": "You are a professional cryptocurrency trading AI."
                            },
                            {
                                "role": "user",
                                "content": sample["input"]["prompt"]
                            },
                            {
                                "role": "assistant",
                                "content": json.dumps(sample["output"]["decision"], ensure_ascii=False)
                            }
                        ],
                        "metadata": sample.get("metadata", {})
                    }
                    
                    f.write(json.dumps(training_item, ensure_ascii=False) + '\n')
            
            logger.info(f"âœ… è®­ç»ƒæ•°æ®å·²å¯¼å‡º: {output_path} ({len(samples)} æ ·æœ¬)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºè®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            return False
    
    async def get_collection_stats(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> Dict[str, Any]:
        """
        è·å–æ•°æ®æ”¶é›†ç»Ÿè®¡
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            query = f"""
            SELECT 
                COUNT(*) as total_decisions,
                SUM(CASE WHEN executed THEN 1 ELSE 0 END) as executed_count,
                COUNT(t.id) as completed_trades,
                AVG(t.pnl) as avg_pnl,
                SUM(CASE WHEN t.pnl > 0 THEN 1 ELSE 0 END) as profitable_trades
            FROM ai_decisions d
            LEFT JOIN trades t ON t.decision_id = d.id AND t.status = 'closed'
            WHERE d.timestamp >= '{start_date.isoformat()}'
              AND d.timestamp <= '{end_date.isoformat()}'
            """
            
            result = await self.db.execute(query)
            row = result.first()
            
            if row:
                total_decisions = row[0] or 0
                completed_trades = row[2] or 0
                profitable_trades = row[4] or 0
                
                return {
                    "date_range": {
                        "start": start_date.isoformat(),
                        "end": end_date.isoformat()
                    },
                    "total_decisions": total_decisions,
                    "executed_count": row[1] or 0,
                    "completed_trades": completed_trades,
                    "avg_pnl": float(row[3]) if row[3] else 0.0,
                    "profitable_trades": profitable_trades,
                    "win_rate": (
                        (profitable_trades / completed_trades * 100)
                        if completed_trades > 0
                        else 0.0
                    )
                }
            
            return {}
            
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}

