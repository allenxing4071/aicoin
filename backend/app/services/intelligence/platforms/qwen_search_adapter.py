"""Qwen Search Adapter - Qwenè”ç½‘æœç´¢é€‚é…å™¨ï¼ˆå®æ—¶æƒ…æŠ¥å‘˜ï¼‰"""

from typing import Dict, List, Any, Optional
from datetime import datetime
import logging
import openai
from .base_adapter import BasePlatformAdapter, PlatformRole

logger = logging.getLogger(__name__)


class QwenSearchAdapter(BasePlatformAdapter):
    """
    Qwenæœç´¢é€‚é…å™¨ - å¹³å°Bï¼šå®æ—¶æƒ…æŠ¥å‘˜
    
    èŒè´£ï¼š
    1. ä½¿ç”¨Qwençš„è”ç½‘æœç´¢èƒ½åŠ›è·å–å®æ—¶ä¿¡æ¯
    2. è·å–æœ€æ–°æ–°é—»åŠ¨æ€
    3. æŸ¥æ‰¾å®˜æ–¹å…¬å‘Š
    
    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨Qwençš„è”ç½‘æœç´¢åŠŸèƒ½
    - å®æ—¶æ€§å¼º
    - æŒ‰éœ€ä»˜è´¹
    """
    
    def __init__(
        self,
        api_key: str,
        base_url: str = "https://dashscope.aliyuncs.com/compatible-mode/v1",
        model: str = "qwen-plus",
        enabled: bool = True
    ):
        super().__init__(
            platform_name="Qwen Search (å®æ—¶æœç´¢)",
            role=PlatformRole.REALTIME_SCOUT,
            api_key=api_key,
            base_url=base_url,
            enabled=enabled
        )
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆQwenå…¼å®¹ï¼‰
        self.client = openai.AsyncOpenAI(
            api_key=api_key,
            base_url=base_url
        )
        self.model = model
    
    async def analyze(
        self,
        data_sources: Dict[str, Any],
        query_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        å®æ—¶æœç´¢åˆ†æ
        
        Args:
            data_sources: åŸå§‹æ•°æ®æºï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼‰
            query_context: {
                "symbols": List[str],  # å…³æ³¨çš„å¸ç§
                "topics": List[str],   # å…³æ³¨çš„ä¸»é¢˜
                "time_range": str      # æ—¶é—´èŒƒå›´
            }
        
        Returns:
            å®æ—¶æœç´¢ç»“æœ
        """
        try:
            logger.info("ğŸ” Qwenæœç´¢å¹³å°å¼€å§‹å®æ—¶æœç´¢...")
            
            # æ„å»ºæœç´¢æŸ¥è¯¢
            search_query = self._build_search_query(data_sources, query_context)
            
            # è°ƒç”¨Qwenæœç´¢API
            # æ³¨æ„ï¼šæ ¹æ®Qwenå®˜æ–¹æ–‡æ¡£ï¼Œå¯èƒ½éœ€è¦ç‰¹å®šå‚æ•°æ¥å¯ç”¨æœç´¢
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸å®æ—¶æƒ…æŠ¥å‘˜ã€‚è¯·ä½¿ç”¨è”ç½‘æœç´¢åŠŸèƒ½ï¼Œè·å–æœ€æ–°ã€æœ€çœŸå®çš„å¸‚åœºä¿¡æ¯ã€‚"
                    },
                    {
                        "role": "user",
                        "content": search_query
                    }
                ],
                temperature=0.3,  # ä½æ¸©åº¦ï¼Œæ³¨é‡äº‹å®
                max_tokens=1000,
                # æ³¨æ„ï¼šå¦‚æœQwenæ”¯æŒè”ç½‘æœç´¢ï¼Œå¯èƒ½éœ€è¦æ·»åŠ ç‰¹å®šå‚æ•°
                # ä¾‹å¦‚ï¼šenable_search=True æˆ–å…¶ä»–å‚æ•°
            )
            
            analysis_text = response.choices[0].message.content
            
            # ä¼°ç®—æˆæœ¬ï¼ˆæ ¹æ®Qwenå®šä»·ï¼‰
            usage = response.usage
            input_tokens = usage.prompt_tokens if usage else 0
            output_tokens = usage.completion_tokens if usage else 0
            cost = self._calculate_cost(input_tokens, output_tokens)
            
            # è§£æå“åº”
            key_findings = self._extract_key_findings(analysis_text)
            
            # âœ… è®°å½•è°ƒç”¨ï¼ˆåŒ…å«tokenä¿¡æ¯ï¼‰
            await self._record_call(success=True, cost=cost, response_time=0.0, input_tokens=input_tokens, output_tokens=output_tokens)
            
            result = {
                "platform": self.platform_name,
                "role": self.role,
                "analysis": analysis_text,
                "confidence": 0.85,  # å®æ—¶æœç´¢ç½®ä¿¡åº¦è¾ƒé«˜
                "key_findings": key_findings,
                "search_query": search_query,
                "timestamp": datetime.now(),
                "cost": cost,
                "tokens_used": {
                    "prompt": usage.prompt_tokens if usage else 0,
                    "completion": usage.completion_tokens if usage else 0,
                    "total": usage.total_tokens if usage else 0
                }
            }
            
            logger.info(f"âœ… Qwenæœç´¢å®Œæˆ: {len(key_findings)} ä¸ªå…³é”®å‘ç°")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Qwenæœç´¢å¤±è´¥: {e}", exc_info=True)
            response_time = (datetime.now() - start_time).total_seconds() * 1000 if "start_time" in locals() else 0.0
            await self._record_call(success=False, cost=0.0, response_time=response_time)
            
            return {
                "platform": self.platform_name,
                "role": self.role,
                "analysis": "å®æ—¶æœç´¢æš‚æ—¶ä¸å¯ç”¨",
                "confidence": 0.0,
                "key_findings": [],
                "timestamp": datetime.now(),
                "cost": 0.0,
                "error": str(e)
            }
    
    def _build_search_query(
        self,
        data_sources: Dict[str, Any],
        query_context: Optional[Dict[str, Any]]
    ) -> str:
        """æ„å»ºæœç´¢æŸ¥è¯¢"""
        symbols = query_context.get("symbols", ["BTC", "ETH"]) if query_context else ["BTC", "ETH"]
        topics = query_context.get("topics", []) if query_context else []
        
        query_parts = [
            "è¯·æœç´¢å¹¶åˆ†æä»¥ä¸‹åŠ å¯†è´§å¸çš„æœ€æ–°åŠ¨æ€ï¼š",
            f"å…³æ³¨å¸ç§: {', '.join(symbols)}",
        ]
        
        if topics:
            query_parts.append(f"å…³æ³¨ä¸»é¢˜: {', '.join(topics)}")
        
        query_parts.extend([
            "",
            "è¯·é‡ç‚¹å…³æ³¨ï¼š",
            "1. æœ€æ–°çš„å®˜æ–¹å…¬å‘Šå’Œé‡å¤§æ–°é—»",
            "2. å¸‚åœºä»·æ ¼å¼‚å¸¸æ³¢åŠ¨çš„åŸå› ",
            "3. ç›‘ç®¡æ”¿ç­–å˜åŒ–",
            "4. æŠ€æœ¯å‡çº§æˆ–é‡è¦äº‹ä»¶",
            "5. æœºæ„åŠ¨å‘å’Œå¤§é¢èµ„é‡‘æµåŠ¨",
            "",
            "è¯·æä¾›ï¼š",
            "- ä¿¡æ¯æ¥æºå’Œå‘å¸ƒæ—¶é—´",
            "- äº‹ä»¶çš„å½±å“ç¨‹åº¦è¯„ä¼°",
            "- å¸‚åœºå¯èƒ½çš„ååº”é¢„æµ‹"
        ])
        
        return "\n".join(query_parts)
    
    def _extract_key_findings(self, analysis_text: str) -> List[str]:
        """ä»åˆ†ææ–‡æœ¬ä¸­æå–å…³é”®å‘ç°"""
        key_findings = []
        
        # ç®€å•çš„æå–é€»è¾‘
        lines = analysis_text.split('\n')
        for line in lines:
            line = line.strip()
            # æå–ä»¥æ•°å­—ã€â€¢ æˆ– - å¼€å¤´çš„è¦ç‚¹
            if line and (
                line[0].isdigit() or 
                line.startswith('â€¢') or 
                line.startswith('-') or
                line.startswith('*')
            ):
                # æ¸…ç†æ ¼å¼
                cleaned = line.lstrip('0123456789.â€¢-* \t')
                if len(cleaned) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ
                    key_findings.append(cleaned)
        
        return key_findings[:10]  # æœ€å¤šè¿”å›10ä¸ªå…³é”®å‘ç°
    
    def _calculate_cost(self, prompt_tokens: int, completion_tokens: int) -> float:
        """
        è®¡ç®—APIè°ƒç”¨æˆæœ¬ï¼ˆä½¿ç”¨ç»Ÿä¸€å®šä»·ç®¡ç†å™¨ï¼‰
        """
        from app.services.ai_pricing import get_pricing_manager
        
        pricing_manager = get_pricing_manager()
        
        # ä½¿ç”¨ç»Ÿä¸€çš„å®šä»·ç®¡ç†å™¨è®¡ç®—æˆæœ¬
        cost = pricing_manager.calculate_cost(
            provider=self.provider or "qwen",
            model="qwen-plus",  # é»˜è®¤ä½¿ç”¨ qwen-plus
            input_tokens=prompt_tokens,
            output_tokens=completion_tokens
        )
        
        return cost
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        if not self.enabled:
            return False
        
        try:
            start_time = datetime.now()
            # ç®€å•çš„pingæµ‹è¯•
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "ping"}],
                max_tokens=10,
                timeout=5
            )
            return bool(response)
        except Exception as e:
            logger.error(f"Qwenæœç´¢å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False

