"""External Data Sources for Intelligence Gathering"""

import logging
import asyncio
from typing import List, Optional
from datetime import datetime, timedelta
import aiohttp
from .models import NewsItem, WhaleActivity, OnChainMetrics
from app.core.config import settings

logger = logging.getLogger(__name__)


class CryptoNewsAPI:
    """Fetch crypto news from multiple sources (RSS Feeds)"""
    
    def __init__(self):
        # RSSæºé…ç½®ï¼ˆå¯ä»¥ä»æ•°æ®åº“æˆ–RedisåŠ¨æ€åŠ è½½ï¼‰
        self.rss_sources = [
            {
                "name": "CoinDesk",
                "url": "https://www.coindesk.com/arc/outboundfeeds/rss/",
                "enabled": True
            },
            {
                "name": "CoinTelegraph",
                "url": "https://cointelegraph.com/rss",
                "enabled": True
            }
        ]
        # ä»é…ç½®æ–‡ä»¶è¯»å–æ˜¯å¦ä½¿ç”¨Mockæ•°æ®
        self.use_mock = getattr(settings, 'RSS_USE_MOCK', False)  # é»˜è®¤ä½¿ç”¨çœŸå®æ•°æ®
    
    async def fetch_latest_news(self, limit: int = 10) -> List[NewsItem]:
        """Fetch latest crypto news from RSS feeds or mock data"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨çœŸå®RSSæº
            if not self.use_mock and any(source["enabled"] for source in self.rss_sources):
                return await self._fetch_from_rss(limit)
            else:
                return await self._fetch_mock_data(limit)
            
        except Exception as e:
            logger.error(f"âŒ è·å–æ–°é—»å¤±è´¥: {e}")
            return []
    
    async def _fetch_from_rss(self, limit: int) -> List[NewsItem]:
        """ä»çœŸå®RSSæºè·å–æ–°é—»"""
        try:
            import feedparser
            
            all_news = []
            
            for source in self.rss_sources:
                if not source["enabled"]:
                    continue
                
                try:
                    logger.info(f"ğŸ“° æ­£åœ¨è·å– {source['name']} RSS...")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(source["url"], timeout=aiohttp.ClientTimeout(total=10)) as response:
                            if response.status == 200:
                                rss_content = await response.text()
                                feed = feedparser.parse(rss_content)
                                
                                for entry in feed.entries[:5]:  # æ¯ä¸ªæºå–5æ¡
                                    # è§£æå‘å¸ƒæ—¶é—´
                                    published_at = datetime.now()
                                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                                        published_at = datetime(*entry.published_parsed[:6])
                                    
                                    # æå–å†…å®¹æ‘˜è¦
                                    content = entry.get('summary', '') or entry.get('description', '')
                                    if content:
                                        # æ¸…ç†HTMLæ ‡ç­¾
                                        import re
                                        content = re.sub(r'<[^>]+>', '', content)[:200]
                                    
                                    news_item = NewsItem(
                                        title=entry.get('title', 'No Title'),
                                        source=source['name'],
                                        url=entry.get('link', ''),
                                        published_at=published_at,
                                        content=content,
                                        impact="medium",  # é»˜è®¤ä¸­ç­‰å½±å“ï¼Œåç»­ç”±Qwenåˆ†æ
                                        sentiment="neutral"  # é»˜è®¤ä¸­æ€§ï¼Œåç»­ç”±Qwenåˆ†æ
                                    )
                                    all_news.append(news_item)
                                
                                logger.info(f"âœ“ {source['name']}: è·å–åˆ° {len(feed.entries[:5])} æ¡æ–°é—»")
                            else:
                                logger.warning(f"âš ï¸  {source['name']} HTTP {response.status}")
                                
                except Exception as e:
                    logger.error(f"âŒ è·å– {source['name']} å¤±è´¥: {e}")
                    continue
            
            # æŒ‰æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
            all_news.sort(key=lambda x: x.published_at, reverse=True)
            result = all_news[:limit]
            
            logger.info(f"âœ… RSSæºå…±è·å–åˆ° {len(result)} æ¡æ–°é—»")
            return result if result else await self._fetch_mock_data(limit)
            
        except ImportError:
            logger.warning("âš ï¸  feedparseræœªå®‰è£…ï¼Œå›é€€åˆ°Mockæ•°æ®ã€‚è¯·è¿è¡Œ: pip install feedparser")
            return await self._fetch_mock_data(limit)
        except Exception as e:
            logger.error(f"âŒ RSSè§£æå¤±è´¥: {e}ï¼Œå›é€€åˆ°Mockæ•°æ®")
            return await self._fetch_mock_data(limit)
    
    async def _fetch_mock_data(self, limit: int) -> List[NewsItem]:
        """è·å–Mockæ•°æ®ï¼ˆç”¨äºæµ‹è¯•æˆ–RSSæºä¸å¯ç”¨æ—¶ï¼‰"""
        logger.info("ğŸ“ ä½¿ç”¨Mockæ•°æ®ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
        
            mock_news = [
                {
                    "title": "Bitcoinçªç ´10ä¸‡ç¾å…ƒå¤§å…³ï¼Œæœºæ„ä¹°ç›˜å¼ºåŠ²",
                    "source": "CoinDesk",
                    "url": "https://coindesk.com/btc-100k",
                    "published_at": datetime.now() - timedelta(hours=2),
                    "content": "æ¯”ç‰¹å¸ä»·æ ¼çªç ´å†å²æ–°é«˜ï¼Œä¸»è¦ç”±æœºæ„æŠ•èµ„è€…æ¨åŠ¨...",
                    "impact": "high",
                    "sentiment": "bullish"
                },
                {
                    "title": "ä»¥å¤ªåŠLayer2æ´»è·ƒåº¦åˆ›æ–°é«˜",
                    "source": "Decrypt",
                    "url": "https://decrypt.co/eth-l2",
                    "published_at": datetime.now() - timedelta(hours=5),
                    "content": "Arbitrumå’ŒOptimismäº¤æ˜“é‡æ¿€å¢...",
                    "impact": "medium",
                    "sentiment": "bullish"
                },
                {
                    "title": "ç¾è”å‚¨ä¼šè®®çºªè¦ï¼šåŠ æ¯å‘¨æœŸå¯èƒ½æ¥è¿‘å°¾å£°",
                    "source": "Reuters",
                    "url": "https://reuters.com/fed",
                    "published_at": datetime.now() - timedelta(hours=8),
                    "content": "è”å‚¨å®˜å‘˜æš—ç¤ºå¯èƒ½æš‚åœåŠ æ¯...",
                    "impact": "high",
                    "sentiment": "neutral"
                }
            ]
            
        news_items = []
            for item in mock_news[:limit]:
                news_items.append(NewsItem(
                    title=item["title"],
                    source=item["source"],
                    url=item["url"],
                    published_at=item["published_at"],
                    content=item["content"],
                    impact=item["impact"],
                    sentiment=item["sentiment"]
                ))
            
        logger.info(f"âœ… Mockæ•°æ®: {len(news_items)} æ¡æ–°é—»")
            return news_items


class OnChainDataAPI:
    """Fetch on-chain data and whale activity"""
    
    def __init__(self):
        self.whale_threshold_usd = 1_000_000  # $1M+ transactions
    
    async def detect_whale_activity(self, symbols: List[str] = None) -> List[WhaleActivity]:
        """Detect recent whale transactions"""
        try:
            if symbols is None:
                symbols = ["BTC", "ETH", "SOL"]
            
            whale_activities = []
            
            # Mock data (replace with real API like Whale Alert, Etherscan, etc.)
            mock_whales = [
                {
                    "symbol": "BTC",
                    "action": "buy",
                    "amount_usd": 15_000_000,
                    "address": "bc1q...xyz",
                    "timestamp": datetime.now() - timedelta(hours=1),
                    "exchange": "Binance"
                },
                {
                    "symbol": "ETH",
                    "action": "transfer",
                    "amount_usd": 8_000_000,
                    "address": "0x...abc",
                    "timestamp": datetime.now() - timedelta(hours=3),
                    "exchange": None
                },
                {
                    "symbol": "SOL",
                    "action": "sell",
                    "amount_usd": 2_500_000,
                    "address": "Sol...def",
                    "timestamp": datetime.now() - timedelta(hours=6),
                    "exchange": "Coinbase"
                }
            ]
            
            for whale in mock_whales:
                if whale["symbol"] in symbols:
                    whale_activities.append(WhaleActivity(
                        symbol=whale["symbol"],
                        action=whale["action"],
                        amount_usd=whale["amount_usd"],
                        address=whale["address"],
                        timestamp=whale["timestamp"],
                        exchange=whale["exchange"]
                    ))
            
            logger.info(f"ğŸ‹ æ£€æµ‹åˆ° {len(whale_activities)} ä¸ªå·¨é²¸æ´»åŠ¨")
            return whale_activities
            
        except Exception as e:
            logger.error(f"âŒ æ£€æµ‹å·¨é²¸æ´»åŠ¨å¤±è´¥: {e}")
            return []
    
    async def fetch_on_chain_metrics(self) -> OnChainMetrics:
        """Fetch current on-chain metrics"""
        try:
            # Mock data (replace with real API like Glassnode, CryptoQuant)
            metrics = OnChainMetrics(
                exchange_net_flow=-50_000_000,  # Negative = outflow (bullish)
                active_addresses=1_250_000,
                gas_price=25.5,  # Gwei
                transaction_volume=5_000_000_000,  # $5B
                timestamp=datetime.now()
            )
            
            logger.info(f"ğŸ“Š è·å–é“¾ä¸ŠæŒ‡æ ‡æˆåŠŸ")
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ è·å–é“¾ä¸ŠæŒ‡æ ‡å¤±è´¥: {e}")
            # Return default metrics
            return OnChainMetrics(
                exchange_net_flow=0,
                active_addresses=0,
                gas_price=0,
                transaction_volume=0,
                timestamp=datetime.now()
            )


# Singleton instances
crypto_news_api = CryptoNewsAPI()
on_chain_data_api = OnChainDataAPI()

