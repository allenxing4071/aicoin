"""Multi-Platform Coordinator - å¤šå¹³å°åè°ƒå™¨ï¼ˆAIé¡¾é—®å§”å‘˜ä¼šåè°ƒä¸­å¿ƒï¼‰"""

from typing import Dict, List, Any, Optional
from datetime import datetime
import logging
import asyncio

from .platforms import (
    BasePlatformAdapter,
    FreePlatformAdapter,
    QwenSearchAdapter,
    QwenDeepAdapter
)
from .cloud_platform_coordinator import CloudPlatformCoordinator

logger = logging.getLogger(__name__)


class MultiPlatformCoordinator:
    """
    å¤šå¹³å°åè°ƒå™¨ - AIé¡¾é—®å§”å‘˜ä¼šåè°ƒä¸­å¿ƒ
    
    èŒè´£ï¼š
    1. ç®¡ç†å¤šä¸ªAIå¹³å°é€‚é…å™¨
    2. åè°ƒå¹³å°é—´çš„åä½œæµç¨‹
    3. æ•´åˆå„å¹³å°çš„åˆ†æç»“æœ
    4. ä¼˜åŒ–å¹³å°è°ƒç”¨ç­–ç•¥
    
    å·¥ä½œæµç¨‹ï¼š
    1. å…è´¹å¹³å°ï¼ˆå¹³å°Aï¼‰ï¼šå¿«é€Ÿç­›é€‰é«˜ä»·å€¼ä¿¡æ¯
    2. Qwenè”ç½‘æœç´¢ï¼ˆå¹³å°Bï¼‰ï¼šè¡¥å……å®æ—¶åŠ¨æ€
    3. Qwenæ·±åº¦åˆ†æï¼ˆå¹³å°Cï¼‰ï¼šç»¼åˆç ”åˆ¤ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    
    æ³¨æ„ï¼šæ‰€æœ‰æœç´¢å’Œåˆ†æéƒ½ç”±Qwenè´Ÿè´£ï¼ŒDeepSeekåªè´Ÿè´£äº¤æ˜“å†³ç­–
    """
    
    def __init__(
        self,
        free_platform: Optional[FreePlatformAdapter] = None,
        search_platform: Optional[QwenSearchAdapter] = None,
        deep_platform: Optional[QwenDeepAdapter] = None
    ):
        """
        åˆå§‹åŒ–å¤šå¹³å°åè°ƒå™¨
        
        Args:
            free_platform: å…è´¹å¹³å°é€‚é…å™¨
            search_platform: æœç´¢å¹³å°é€‚é…å™¨
            deep_platform: æ·±åº¦åˆ†æå¹³å°é€‚é…å™¨
        """
        self.platforms: Dict[str, BasePlatformAdapter] = {}
        
        if free_platform:
            self.platforms["free"] = free_platform
        if search_platform:
            self.platforms["search"] = search_platform
        if deep_platform:
            self.platforms["deep"] = deep_platform
        
        # åˆå§‹åŒ–äº‘å¹³å°å¹¶è¡Œåè°ƒå™¨ï¼ˆæ ¸å¿ƒï¼šä¸‰å¹³å°åŒæ—¶è°ƒç”¨ï¼‰
        self.cloud_coordinator = CloudPlatformCoordinator()
        
        self.coordination_history: List[Dict[str, Any]] = []
        
        logger.info(f"âœ… å¤šå¹³å°åè°ƒå™¨åˆå§‹åŒ–å®Œæˆï¼Œå·²æ³¨å†Œ {len(self.platforms)} ä¸ªå¹³å° + äº‘å¹³å°å¹¶è¡Œåè°ƒå™¨")
    
    async def coordinate_analysis(
        self,
        data_sources: Dict[str, Any],
        query_context: Optional[Dict[str, Any]] = None,
        use_all_platforms: bool = True
    ) -> Dict[str, Any]:
        """
        åè°ƒå¤šå¹³å°åˆ†æ
        
        Args:
            data_sources: åŸå§‹æ•°æ®æº
            query_context: æŸ¥è¯¢ä¸Šä¸‹æ–‡
            use_all_platforms: æ˜¯å¦ä½¿ç”¨æ‰€æœ‰å¹³å°ï¼ˆå¦åˆ™æ™ºèƒ½é€‰æ‹©ï¼‰
        
        Returns:
            æ•´åˆåçš„ç»¼åˆåˆ†ææŠ¥å‘Š
        """
        start_time = datetime.now()
        logger.info("ğŸ¯ å¤šå¹³å°åè°ƒåˆ†æå¼€å§‹...")
        
        try:
            results = {}
            total_cost = 0.0
            
            # === é˜¶æ®µ1ï¼šå…è´¹å¹³å°å¿«é€Ÿç­›é€‰ ===
            if "free" in self.platforms and self.platforms["free"].enabled:
                logger.info("ğŸ“Š é˜¶æ®µ1: å…è´¹å¹³å°å¿«é€Ÿç­›é€‰...")
                free_result = await self.platforms["free"].analyze(
                    data_sources=data_sources,
                    query_context=query_context
                )
                results["free_platform"] = free_result
                total_cost += free_result.get("cost", 0.0)
                
                logger.info(f"âœ“ å…è´¹å¹³å°ç­›é€‰å®Œæˆï¼Œå‘ç° {len(free_result.get('key_findings', []))} ä¸ªå…³é”®ç‚¹")
            
            # === é˜¶æ®µ2ï¼šäº‘å¹³å°å¹¶è¡Œæœç´¢ä¸äº¤å‰éªŒè¯ï¼ˆæ ¸å¿ƒå‡çº§ï¼‰===
            should_search = self._should_use_search(results, query_context)
            
            if should_search:
                logger.info("ğŸ” é˜¶æ®µ2: äº‘å¹³å°å¹¶è¡Œæœç´¢ä¸äº¤å‰éªŒè¯...")
                
                # ä½¿ç”¨äº‘å¹³å°åè°ƒå™¨ï¼šåŒæ—¶è°ƒç”¨ä¸‰å¤§å¹³å°ï¼ˆç™¾åº¦+è…¾è®¯+ç«å±±ï¼‰
                cloud_search_result = await self.cloud_coordinator.parallel_search_and_verify(
                    data_sources=data_sources,
                    query_context=query_context
                )
                results["cloud_platforms"] = cloud_search_result
                
                # è®°å½•éªŒè¯å…ƒæ•°æ®
                metadata = cloud_search_result.get("verification_metadata", {})
                logger.info(
                    f"âœ“ äº‘å¹³å°å¹¶è¡ŒéªŒè¯å®Œæˆ: "
                    f"{metadata.get('successful_platforms', 0)}/{metadata.get('total_platforms_called', 0)} ä¸ªå¹³å°æˆåŠŸ, "
                    f"å…±è¯†åº¦={metadata.get('platform_consensus', 0):.1%}, "
                    f"ç½®ä¿¡åº¦={cloud_search_result.get('confidence', 0):.2f}"
                )
                
                # å¦‚æœè¿˜é…ç½®äº†åŸæœ‰çš„searchå¹³å°ï¼Œä¹Ÿè°ƒç”¨ï¼ˆå…¼å®¹æ€§ï¼‰
                if "search" in self.platforms and self.platforms["search"].enabled:
                    logger.info("ğŸ” è¡¥å……: Qwen DashScopeæœç´¢...")
                    search_result = await self.platforms["search"].analyze(
                        data_sources=data_sources,
                        query_context=query_context
                    )
                    results["search_platform"] = search_result
                    total_cost += search_result.get("cost", 0.0)
            
            # === é˜¶æ®µ3ï¼šæ·±åº¦ç»¼åˆåˆ†æ ===
            if "deep" in self.platforms and self.platforms["deep"].enabled:
                logger.info("ğŸ§  é˜¶æ®µ3: Qwenæ·±åº¦ç»¼åˆåˆ†æ...")
                
                # æ„å»ºæ·±åº¦åˆ†æçš„è¾“å…¥ï¼ˆåŒ…å«äº‘å¹³å°éªŒè¯ç»“æœï¼‰
                deep_input = {
                    "raw_data": data_sources,
                    "free_platform_result": results.get("free_platform"),
                    "search_result": results.get("search_platform"),
                    "cloud_platforms_result": results.get("cloud_platforms")  # æ–°å¢ï¼šäº‘å¹³å°éªŒè¯ç»“æœ
                }
                
                deep_result = await self.platforms["deep"].analyze(
                    data_sources=deep_input,
                    query_context=query_context
                )
                results["deep_platform"] = deep_result
                total_cost += deep_result.get("cost", 0.0)
                
                logger.info(f"âœ“ æ·±åº¦åˆ†æå®Œæˆï¼Œç½®ä¿¡åº¦ {deep_result.get('confidence', 0):.2f}")
            
            # === æ•´åˆæœ€ç»ˆæŠ¥å‘Š ===
            final_report = self._integrate_results(results, data_sources)
            final_report["coordination_metadata"] = {
                "platforms_used": list(results.keys()),
                "total_cost": total_cost,
                "processing_time_seconds": (datetime.now() - start_time).total_seconds(),
                "timestamp": datetime.now()
            }
            
            # è®°å½•åè°ƒå†å²
            self._record_coordination(final_report)
            
            logger.info(
                f"âœ… å¤šå¹³å°åè°ƒå®Œæˆ: "
                f"ä½¿ç”¨{len(results)}ä¸ªå¹³å°, "
                f"è€—æ—¶{final_report['coordination_metadata']['processing_time_seconds']:.2f}ç§’, "
                f"æˆæœ¬${total_cost:.4f}"
            )
            
            return final_report
        
        except Exception as e:
            logger.error(f"âŒ å¤šå¹³å°åè°ƒå¤±è´¥: {e}", exc_info=True)
            
            return {
                "error": str(e),
                "platforms_attempted": list(self.platforms.keys()),
                "timestamp": datetime.now(),
                "success": False
            }
    
    def _should_use_search(
        self,
        preliminary_results: Dict[str, Any],
        query_context: Optional[Dict[str, Any]]
    ) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å®æ—¶æœç´¢
        
        ç­–ç•¥ï¼š
        1. å¦‚æœå…è´¹å¹³å°å‘ç°é«˜å½±å“åŠ›äº‹ä»¶ -> ä½¿ç”¨æœç´¢
        2. å¦‚æœç”¨æˆ·æ˜ç¡®è¦æ±‚å®æ—¶ä¿¡æ¯ -> ä½¿ç”¨æœç´¢
        3. å¦‚æœå¸‚åœºå¼‚å¸¸æ³¢åŠ¨ -> ä½¿ç”¨æœç´¢
        4. é»˜è®¤ï¼šä¸ä½¿ç”¨ï¼ˆèŠ‚çœæˆæœ¬ï¼‰
        """
        # ç­–ç•¥1ï¼šæ£€æŸ¥å…è´¹å¹³å°ç»“æœ
        free_result = preliminary_results.get("free_platform", {})
        high_impact_count = len([
            f for f in free_result.get("key_findings", [])
            if any(keyword in f for keyword in ["ç›‘ç®¡", "é»‘å®¢", "é‡å¤§", "çªç ´"])
        ])
        
        if high_impact_count >= 2:
            logger.info("ğŸ¯ æ£€æµ‹åˆ°é‡å¤§äº‹ä»¶ï¼Œå¯ç”¨å®æ—¶æœç´¢")
            return True
        
        # ç­–ç•¥2ï¼šç”¨æˆ·æ˜ç¡®è¦æ±‚
        if query_context and query_context.get("require_realtime", False):
            logger.info("ğŸ¯ ç”¨æˆ·è¦æ±‚å®æ—¶ä¿¡æ¯ï¼Œå¯ç”¨æœç´¢")
            return True
        
        # ç­–ç•¥3ï¼šå¸‚åœºå¼‚å¸¸ï¼ˆå¯ä»¥åç»­æ‰©å±•ï¼‰
        # TODO: æ£€æŸ¥ä»·æ ¼æ³¢åŠ¨ã€äº¤æ˜“é‡å¼‚å¸¸ç­‰
        
        # é»˜è®¤ä¸ä½¿ç”¨
        logger.info("ğŸ’¡ å¸¸è§„æƒ…å†µï¼Œè·³è¿‡å®æ—¶æœç´¢ä»¥èŠ‚çœæˆæœ¬")
        return False
    
    def _integrate_results(
        self,
        platform_results: Dict[str, Any],
        original_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ•´åˆå„å¹³å°ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        
        æ•´åˆç­–ç•¥ï¼š
        - ä»¥Qwenæ·±åº¦åˆ†æä¸ºä¸»ä½“
        - è¡¥å……å…¶ä»–å¹³å°çš„å…³é”®å‘ç°
        - èšåˆé£é™©å’Œæœºä¼š
        """
        deep_result = platform_results.get("deep_platform", {})
        free_result = platform_results.get("free_platform", {})
        search_result = platform_results.get("search_platform", {})
        
        # åŸºç¡€ç»“æ„
        integrated = {
            "timestamp": datetime.now(),
            "platforms_used": list(platform_results.keys()),
            "success": True
        }
        
        # ä¸»è¦åˆ†æï¼ˆä¼˜å…ˆä½¿ç”¨æ·±åº¦åˆ†æï¼‰
        if deep_result:
            integrated.update({
                "analysis": deep_result.get("analysis", ""),
                "market_sentiment": deep_result.get("market_sentiment", "neutral"),
                "sentiment_score": deep_result.get("sentiment_score", 0.0),
                "confidence": deep_result.get("confidence", 0.8)
            })
        elif free_result:
            integrated.update({
                "analysis": free_result.get("analysis", ""),
                "market_sentiment": "neutral",
                "sentiment_score": 0.0,
                "confidence": 0.6
            })
        
        # èšåˆå…³é”®å‘ç°
        all_findings = []
        for platform_key, result in platform_results.items():
            findings = result.get("key_findings", [])
            for finding in findings:
                if finding not in all_findings:  # å»é‡
                    all_findings.append(finding)
        integrated["key_findings"] = all_findings[:10]  # æœ€å¤š10ä¸ª
        
        # èšåˆé£é™©å› ç´ 
        all_risks = []
        if deep_result:
            all_risks.extend(deep_result.get("risk_factors", []))
        integrated["risk_factors"] = all_risks[:5]  # æœ€å¤š5ä¸ª
        
        # èšåˆæœºä¼šç‚¹
        all_opportunities = []
        if deep_result:
            all_opportunities.extend(deep_result.get("opportunities", []))
        integrated["opportunities"] = all_opportunities[:3]  # æœ€å¤š3ä¸ª
        
        # å¹³å°è´¡çŒ®æ˜ç»†
        integrated["platform_contributions"] = {
            platform_key: {
                "role": result.get("role", ""),
                "confidence": result.get("confidence", 0.0),
                "cost": result.get("cost", 0.0),
                "findings_count": len(result.get("key_findings", []))
            }
            for platform_key, result in platform_results.items()
        }
        
        return integrated
    
    def _record_coordination(self, report: Dict[str, Any]):
        """è®°å½•åè°ƒå†å²"""
        self.coordination_history.append({
            "timestamp": report.get("timestamp"),
            "platforms_used": report.get("platforms_used", []),
            "total_cost": report.get("coordination_metadata", {}).get("total_cost", 0.0),
            "confidence": report.get("confidence", 0.0),
            "success": report.get("success", False)
        })
        
        # åªä¿ç•™æœ€è¿‘100æ¡
        if len(self.coordination_history) > 100:
            self.coordination_history = self.coordination_history[-100:]
    
    async def health_check_all(self) -> Dict[str, bool]:
        """æ£€æŸ¥æ‰€æœ‰å¹³å°å¥åº·çŠ¶æ€"""
        results = {}
        
        for platform_name, platform in self.platforms.items():
            try:
                results[platform_name] = await platform.health_check()
            except Exception as e:
                logger.error(f"å¹³å° {platform_name} å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
                results[platform_name] = False
        
        return results
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–åè°ƒå™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_coordinations": len(self.coordination_history),
            "platforms": {
                name: platform.get_statistics()
                for name, platform in self.platforms.items()
            },
            "recent_coordinations": self.coordination_history[-10:]  # æœ€è¿‘10æ¬¡
        }

