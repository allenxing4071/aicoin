"""Qwen Intelligence Engine - Market Intelligence Officer"""

import logging
from datetime import datetime
from typing import List, Optional
import openai
from app.core.config import settings
from app.utils.timezone import get_beijing_time
from .models import IntelligenceReport, SentimentType
from .data_sources import crypto_news_api, on_chain_data_api
from .storage import intelligence_storage

logger = logging.getLogger(__name__)


class QwenIntelligenceEngine:
    """
    Qwenä½œä¸ºæƒ…æŠ¥å®˜(Intelligence Officer)
    è´Ÿè´£æ”¶é›†å’Œåˆ†æå¸‚åœºæƒ…æŠ¥ï¼Œä¸ç›´æ¥å‚ä¸äº¤æ˜“å†³ç­–
    """
    
    def __init__(self):
        self.client = openai.AsyncOpenAI(
            api_key=settings.QWEN_API_KEY,
            base_url=settings.QWEN_BASE_URL
        )
        self.model = settings.QWEN_MODEL
        self.is_running = False
        self.last_report_time: Optional[datetime] = None
    
    async def collect_intelligence(self) -> IntelligenceReport:
        """
        æ”¶é›†å®Œæ•´çš„å¸‚åœºæƒ…æŠ¥
        è¿™æ˜¯ä¸»å…¥å£æ–¹æ³•ï¼Œåè°ƒæ‰€æœ‰æƒ…æŠ¥æ”¶é›†å·¥ä½œ
        """
        try:
            logger.info("ğŸ•µï¸â€â™€ï¸ Qwenæƒ…æŠ¥å®˜å¼€å§‹æ”¶é›†æƒ…æŠ¥...")
            
            # å¹¶å‘æ”¶é›†æ‰€æœ‰æ•°æ®
            news_items = await crypto_news_api.fetch_latest_news(limit=10)
            whale_signals = await on_chain_data_api.detect_whale_activity()
            on_chain_metrics = await on_chain_data_api.fetch_on_chain_metrics()
            
            # ä½¿ç”¨Qwenåˆ†ææ‰€æœ‰æƒ…æŠ¥
            report = await self.generate_intelligence_report(
                news_items=news_items,
                whale_signals=whale_signals,
                on_chain_metrics=on_chain_metrics
            )
            
            # å­˜å‚¨æŠ¥å‘Š
            await intelligence_storage.store_report(report)
            self.last_report_time = report.timestamp
            
            logger.info(f"âœ… Qwenæƒ…æŠ¥æŠ¥å‘Šç”Ÿæˆå®Œæˆ: æƒ…ç»ª={report.market_sentiment.value}, ç½®ä¿¡åº¦={report.confidence:.2f}")
            return report
            
        except Exception as e:
            logger.error(f"âŒ Qwenæƒ…æŠ¥æ”¶é›†å¤±è´¥: {e}", exc_info=True)
            # Return a minimal report
            return self._create_fallback_report()
    
    async def generate_intelligence_report(
        self,
        news_items: List,
        whale_signals: List,
        on_chain_metrics
    ) -> IntelligenceReport:
        """ä½¿ç”¨Qwenåˆ†ææ‰€æœ‰æƒ…æŠ¥å¹¶ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        import time
        
        try:
            # æ„å»ºåˆ†æprompt
            prompt = self._build_analysis_prompt(news_items, whale_signals, on_chain_metrics)
            
            # è°ƒç”¨Qwenè¿›è¡Œåˆ†æ
            start_time = time.time()
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸å¸‚åœºæƒ…æŠ¥åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå¸‚åœºæ•°æ®ã€æ–°é—»å’Œé“¾ä¸Šä¿¡æ¯ï¼Œä¸ºäº¤æ˜“AIæä¾›å®¢è§‚ã€å…¨é¢çš„æƒ…æŠ¥æŠ¥å‘Šã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,  # Lower temperature for more factual analysis
                max_tokens=1500
            )
            response_time = time.time() - start_time
            
            # æå–tokenå’Œæˆæœ¬ä¿¡æ¯
            input_tokens = 0
            output_tokens = 0
            cost = 0.0
            
            if hasattr(response, 'usage') and response.usage:
                input_tokens = response.usage.prompt_tokens
                output_tokens = response.usage.completion_tokens
                # Qwenå®šä»·ï¼šè¾“å…¥Â¥4/M, è¾“å‡ºÂ¥12/M
                cost = (input_tokens / 1_000_000 * 4.0) + (output_tokens / 1_000_000 * 12.0)
            
            # å¼‚æ­¥è®°å½•ä½¿ç”¨æ—¥å¿—ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
            try:
                from app.core.database import AsyncSessionLocal
                from app.services.ai_usage_logger import log_ai_call
                
                async with AsyncSessionLocal() as db:
                    await log_ai_call(
                        db=db,
                        model_name=self.model,
                        input_tokens=input_tokens,
                        output_tokens=output_tokens,
                        cost=cost,
                        platform_id=2,  # Qwenå¹³å°IDï¼ˆå‡è®¾ä¸º2ï¼‰
                        success=True,
                        response_time=response_time,
                        purpose="intelligence",
                        request_id=f"intel_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    )
            except Exception as log_error:
                logger.warning(f"è®°å½•Qwenä½¿ç”¨æ—¥å¿—å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {log_error}")
            
            analysis_text = response.choices[0].message.content
            
            # è§£æQwençš„åˆ†æç»“æœ
            sentiment, sentiment_score, risk_factors, opportunities, confidence = self._parse_qwen_analysis(
                analysis_text
            )
            
            # æ„å»ºå®Œæ•´æŠ¥å‘Š
            report = IntelligenceReport(
                timestamp=get_beijing_time(),
                market_sentiment=sentiment,
                sentiment_score=sentiment_score,
                key_news=news_items[:5],  # Top 5 news
                whale_signals=whale_signals,
                on_chain_metrics=on_chain_metrics,
                risk_factors=risk_factors,
                opportunities=opportunities,
                qwen_analysis=analysis_text,
                confidence=confidence
            )
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ Qwenåˆ†æå¤±è´¥: {e}", exc_info=True)
            return self._create_fallback_report()
    
    def _build_analysis_prompt(self, news_items, whale_signals, on_chain_metrics) -> str:
        """æ„å»ºå‘ç»™Qwençš„åˆ†æprompt"""
        prompt = """è¯·åˆ†æä»¥ä¸‹åŠ å¯†è´§å¸å¸‚åœºæƒ…æŠ¥ï¼Œå¹¶æä¾›ä½ çš„ä¸“ä¸šåˆ¤æ–­ï¼š

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“° æœ€æ–°æ–°é—» (Latest News)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        
        for i, news in enumerate(news_items[:5], 1):
            prompt += f"\n{i}. ã€{news.source}ã€‘{news.title}\n"
            if news.content:
                prompt += f"   å†…å®¹: {news.content[:100]}...\n"
            prompt += f"   å½±å“: {news.impact} | æƒ…ç»ª: {news.sentiment}\n"
        
        prompt += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ‹ å·¨é²¸æ´»åŠ¨ (Whale Activity)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        
        for whale in whale_signals:
            action_cn = {"buy": "ä¹°å…¥", "sell": "å–å‡º", "transfer": "è½¬è´¦"}.get(whale.action, whale.action)
            prompt += f"\nâ€¢ {whale.symbol}: {action_cn} ${whale.amount_usd:,.0f}"
            if whale.exchange:
                prompt += f" ({whale.exchange})"
            prompt += "\n"
        
        prompt += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š é“¾ä¸ŠæŒ‡æ ‡ (On-Chain Metrics)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ äº¤æ˜“æ‰€å‡€æµé‡: ${on_chain_metrics.exchange_net_flow:,.0f} (è´Ÿæ•°=æµå‡º=çœ‹æ¶¨)
â€¢ æ´»è·ƒåœ°å€æ•°: {on_chain_metrics.active_addresses:,}
â€¢ Gasä»·æ ¼: {on_chain_metrics.gas_price:.2f} Gwei
â€¢ äº¤æ˜“é‡: ${on_chain_metrics.transaction_volume:,.0f}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ è¯·æä¾›ä½ çš„åˆ†æ (Your Analysis)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºä½ çš„åˆ†æï¼š

1. **å¸‚åœºæƒ…ç»ª** (BULLISH/BEARISH/NEUTRAL): 
2. **æƒ…ç»ªå¼ºåº¦** (-1.0åˆ°1.0çš„æ•°å€¼):
3. **é£é™©å› ç´ ** (åˆ—å‡º3-5ä¸ª):
4. **æœºä¼šç‚¹** (åˆ—å‡º2-3ä¸ª):
5. **ç»¼åˆåˆ†æ** (200å­—ä»¥å†…çš„ä¸“ä¸šåˆ†æ):
6. **ç½®ä¿¡åº¦** (0.0-1.0):

è¯·ä¿æŒå®¢è§‚ï¼ŒåŸºäºæ•°æ®å’Œäº‹å®è¿›è¡Œåˆ†æã€‚
"""
        return prompt
    
    def _parse_qwen_analysis(self, analysis_text: str) -> tuple:
        """è§£æQwençš„åˆ†æç»“æœ"""
        try:
            # ç®€å•è§£æï¼ˆå®é™…é¡¹ç›®ä¸­åº”è¯¥ç”¨æ›´robustçš„æ–¹æ³•ï¼‰
            sentiment = SentimentType.NEUTRAL
            sentiment_score = 0.0
            risk_factors = []
            opportunities = []
            confidence = 0.7
            
            lines = analysis_text.split('\n')
            for line in lines:
                line_lower = line.lower()
                
                if 'bullish' in line_lower or 'çœ‹æ¶¨' in line_lower or 'ä¹è§‚' in line_lower:
                    sentiment = SentimentType.BULLISH
                    sentiment_score = 0.6
                elif 'bearish' in line_lower or 'çœ‹è·Œ' in line_lower or 'æ‚²è§‚' in line_lower:
                    sentiment = SentimentType.BEARISH
                    sentiment_score = -0.6
                
                if 'é£é™©' in line and 'ï¼š' in line:
                    risk = line.split('ï¼š')[1].strip()
                    if risk:
                        risk_factors.append(risk)
                
                if 'æœºä¼š' in line and 'ï¼š' in line:
                    opp = line.split('ï¼š')[1].strip()
                    if opp:
                        opportunities.append(opp)
                
                if 'ç½®ä¿¡åº¦' in line:
                    try:
                        # Extract number from line
                        import re
                        match = re.search(r'(\d+\.?\d*)', line)
                        if match:
                            conf_val = float(match.group(1))
                            confidence = conf_val if conf_val <= 1.0 else conf_val / 100
                    except:
                        pass
            
            # Default values if parsing failed
            if not risk_factors:
                risk_factors = ["å¸‚åœºæ³¢åŠ¨æ€§", "ç›‘ç®¡ä¸ç¡®å®šæ€§", "å®è§‚ç»æµç¯å¢ƒ"]
            if not opportunities:
                opportunities = ["æŠ€æœ¯é¢çªç ´", "æœºæ„èµ„é‡‘æµå…¥"]
            
            return sentiment, sentiment_score, risk_factors, opportunities, confidence
            
        except Exception as e:
            logger.error(f"âŒ è§£æQwenåˆ†æå¤±è´¥: {e}")
            return SentimentType.NEUTRAL, 0.0, ["æ•°æ®ä¸è¶³"], ["è§‚æœ›"], 0.5
    
    def _create_fallback_report(self) -> IntelligenceReport:
        """åˆ›å»ºfallbackæŠ¥å‘Šï¼ˆå½“Qwenå¤±è´¥æ—¶ï¼‰"""
        from .models import OnChainMetrics
        return IntelligenceReport(
            timestamp=get_beijing_time(),
            market_sentiment=SentimentType.NEUTRAL,
            sentiment_score=0.0,
            key_news=[],
            whale_signals=[],
            on_chain_metrics=OnChainMetrics(
                exchange_net_flow=0,
                active_addresses=0,
                gas_price=0,
                transaction_volume=0,
                timestamp=get_beijing_time()
            ),
            risk_factors=["æƒ…æŠ¥ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨"],
            opportunities=[],
            qwen_analysis="æƒ…æŠ¥æ”¶é›†ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®ã€‚",
            confidence=0.3
        )
    
    async def start(self):
        """å¯åŠ¨æƒ…æŠ¥å¼•æ“"""
        self.is_running = True
        logger.info("ğŸ•µï¸â€â™€ï¸ Qwenæƒ…æŠ¥å¼•æ“å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢æƒ…æŠ¥å¼•æ“"""
        self.is_running = False
        logger.info("ğŸ›‘ Qwenæƒ…æŠ¥å¼•æ“å·²åœæ­¢")


# Singleton instance
qwen_intelligence_engine = QwenIntelligenceEngine()

