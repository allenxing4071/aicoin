"""é•¿æœŸè®°å¿†æœåŠ¡ - Qdrantå‘é‡æ•°æ®åº“å®ç°"""

from typing import Dict, List, Any, Optional
from datetime import datetime
import hashlib
import json
import logging

import openai
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct

from app.core.config import settings

logger = logging.getLogger(__name__)


class MarketStateVectorizer:
    """
    å¸‚åœºçŠ¶æ€å‘é‡åŒ–å™¨
    
    æ”¯æŒå¤šç§EmbeddingæœåŠ¡:
    - OpenAI (text-embedding-ada-002)
    - DeepSeek (deepseek-chat with custom embedding)
    - Qwen (text-embedding-v2/v3)
    """
    
    def __init__(
        self, 
        api_key: Optional[str] = None,
        provider: str = "auto",  # auto, openai, deepseek, qwen
        model: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–å‘é‡åŒ–å™¨
        
        Args:
            api_key: APIå¯†é’¥ï¼ˆå¦‚æœä¸ºNoneï¼Œè‡ªåŠ¨ä»settingsè·å–ï¼‰
            provider: embeddingæœåŠ¡æä¾›å•† (autoä¼šè‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„)
            model: æ¨¡å‹åç§°ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼‰
        """
        self.provider = provider
        self.enabled = False
        self.client = None
        self.model = None
        self.vector_dim = 1536  # é»˜è®¤ç»´åº¦
        
        # è‡ªåŠ¨é€‰æ‹©provider
        if provider == "auto":
            if settings.QWEN_API_KEY:
                provider = "qwen"
                api_key = api_key or settings.QWEN_API_KEY
                logger.info("ğŸ” ä½¿ç”¨Qwen EmbeddingæœåŠ¡")
            elif settings.DEEPSEEK_API_KEY:
                provider = "deepseek"
                api_key = api_key or settings.DEEPSEEK_API_KEY
                logger.info("ğŸ” ä½¿ç”¨DeepSeek EmbeddingæœåŠ¡")
            elif settings.OPENAI_API_KEY:
                provider = "openai"
                api_key = api_key or settings.OPENAI_API_KEY
                logger.info("ğŸ” ä½¿ç”¨OpenAI EmbeddingæœåŠ¡")
            else:
                logger.warning("âš ï¸ æœªé…ç½®ä»»ä½•Embedding API Keyï¼Œé•¿æœŸè®°å¿†åŠŸèƒ½å·²ç¦ç”¨")
                return
        
        # éªŒè¯API Key
        if not api_key or api_key.startswith("sk-your-") or api_key == "your-key-here":
            logger.warning(f"âš ï¸ {provider.upper()} API Keyæœªé…ç½®æˆ–æ— æ•ˆï¼Œé•¿æœŸè®°å¿†åŠŸèƒ½å·²ç¦ç”¨")
            return
        
        # åˆå§‹åŒ–å¯¹åº”çš„å®¢æˆ·ç«¯
        try:
            if provider == "qwen":
                self.client = openai.OpenAI(
                    api_key=api_key,
                    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
                )
                self.model = model or "text-embedding-v3"
                self.vector_dim = 1024  # Qwen embeddingç»´åº¦
                self.enabled = True
                logger.info(f"âœ… Qwen Embeddingå·²å¯ç”¨ (æ¨¡å‹: {self.model}, ç»´åº¦: {self.vector_dim})")
                
            elif provider == "deepseek":
                # DeepSeekæš‚ä¸ç›´æ¥æ”¯æŒembeddingï¼Œä½¿ç”¨chatæ¨¡å‹ç”Ÿæˆç‰¹å¾
                self.client = openai.OpenAI(
                    api_key=api_key,
                    base_url="https://api.deepseek.com/v1"
                )
                self.model = model or "deepseek-chat"
                self.vector_dim = 768  # ä½¿ç”¨è¾ƒå°ç»´åº¦
                self.enabled = True
                logger.info(f"âœ… DeepSeekç‰¹å¾æå–å·²å¯ç”¨ (æ¨¡å‹: {self.model}, ç»´åº¦: {self.vector_dim})")
                logger.warning("âš ï¸ DeepSeekæš‚æ— ä¸“ç”¨embeddingæ¥å£ï¼Œä½¿ç”¨ç‰¹å¾å“ˆå¸Œæ–¹æ³•")
                
            elif provider == "openai":
                self.client = openai.OpenAI(api_key=api_key)
                self.model = model or "text-embedding-ada-002"
                self.vector_dim = 1536
                self.enabled = True
                logger.info(f"âœ… OpenAI Embeddingå·²å¯ç”¨ (æ¨¡å‹: {self.model}, ç»´åº¦: {self.vector_dim})")
            
            else:
                logger.error(f"âŒ ä¸æ”¯æŒçš„provider: {provider}")
                
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–{provider}å®¢æˆ·ç«¯å¤±è´¥: {e}")
            self.enabled = False
        
        self.provider = provider
    
    def extract_features(self, market_data: Dict[str, Any], decision: Dict[str, Any]) -> List[float]:
        """
        æå–å¸‚åœºç‰¹å¾å¹¶è½¬æ¢ä¸ºå‘é‡
        
        Returns:
            ç‰¹å¾å‘é‡
        """
        # å¦‚æœæœªå¯ç”¨ï¼Œè¿”å›é›¶å‘é‡
        if not self.enabled:
            return [0.0] * self.vector_dim
        
        # 1. æ„å»ºæ–‡æœ¬æè¿°
        text_description = self._build_text_description(market_data, decision)
        
        # 2. æ ¹æ®providerè°ƒç”¨ç›¸åº”çš„å‘é‡åŒ–æ–¹æ³•
        try:
            if self.provider in ["qwen", "openai"]:
                # Qwenå’ŒOpenAIéƒ½æ”¯æŒæ ‡å‡†çš„embeddingsæ¥å£
                response = self.client.embeddings.create(
                    model=self.model,
                    input=text_description
                )
                return response.data[0].embedding
            
            elif self.provider == "deepseek":
                # DeepSeekä½¿ç”¨ç‰¹å¾å“ˆå¸Œæ–¹æ³•
                # æå–å…³é”®ç‰¹å¾å¹¶ç”Ÿæˆå›ºå®šç»´åº¦å‘é‡
                return self._deepseek_feature_hash(text_description, market_data, decision)
            
            else:
                logger.error(f"ä¸æ”¯æŒçš„provider: {self.provider}")
                return [0.0] * self.vector_dim
        
        except Exception as e:
            logger.error(f"å‘é‡åŒ–å¤±è´¥ ({self.provider}): {e}")
            # è¿”å›é›¶å‘é‡
            return [0.0] * self.vector_dim
    
    def _deepseek_feature_hash(
        self, 
        text_description: str, 
        market_data: Dict[str, Any], 
        decision: Dict[str, Any]
    ) -> List[float]:
        """
        DeepSeekç‰¹å¾å“ˆå¸Œæ–¹æ³•
        
        ç”±äºDeepSeekæš‚æ— embeddingæ¥å£ï¼Œä½¿ç”¨æ•°å€¼ç‰¹å¾ç»„åˆç”Ÿæˆå‘é‡
        """
        import hashlib
        import struct
        
        # æå–æ•°å€¼ç‰¹å¾
        symbol = decision.get("symbol", "BTC")
        action = decision.get("action", "hold")
        confidence = decision.get("confidence", 0.0)
        
        price = market_data.get(symbol, {}).get("price", 0)
        change_24h = market_data.get(symbol, {}).get("change_24h", 0)
        volume = market_data.get(symbol, {}).get("volume_24h", 0)
        
        # å½’ä¸€åŒ–æ•°å€¼ç‰¹å¾
        features = []
        
        # ä»·æ ¼ç›¸å…³ç‰¹å¾ (256ç»´)
        price_hash = hashlib.sha256(str(price).encode()).digest()
        features.extend([b / 255.0 for b in price_hash])
        
        # å˜åŒ–ç›¸å…³ç‰¹å¾ (256ç»´)
        change_hash = hashlib.sha256(str(change_24h).encode()).digest()
        features.extend([b / 255.0 for b in change_hash])
        
        # å†³ç­–ç›¸å…³ç‰¹å¾ (256ç»´)
        decision_str = f"{symbol}_{action}_{confidence}"
        decision_hash = hashlib.sha256(decision_str.encode()).digest()
        features.extend([b / 255.0 for b in decision_hash])
        
        # ç¡®ä¿ç»´åº¦æ­£ç¡® (768ç»´)
        if len(features) < self.vector_dim:
            features.extend([0.0] * (self.vector_dim - len(features)))
        else:
            features = features[:self.vector_dim]
        
        return features
    
    def _build_text_description(self, market_data: Dict[str, Any], decision: Dict[str, Any]) -> str:
        """æ„å»ºå¸‚åœºçŠ¶æ€çš„æ–‡æœ¬æè¿°"""
        
        symbol = decision.get("symbol", "BTC")
        action = decision.get("action", "hold")
        confidence = decision.get("confidence", 0.0)
        
        # æå–å¸‚åœºæ•°æ®
        price = market_data.get(symbol, {}).get("price", 0)
        change_24h = market_data.get(symbol, {}).get("change_24h", 0)
        volume = market_data.get(symbol, {}).get("volume_24h", 0)
        
        # æ„å»ºæè¿°
        description = f"""
        Trading Decision Context:
        - Symbol: {symbol}
        - Current Price: ${price:,.2f}
        - 24h Change: {change_24h:+.2f}%
        - 24h Volume: ${volume:,.0f}
        - Action: {action}
        - Confidence: {confidence:.2f}
        
        Market Sentiment: {'Bullish' if change_24h > 0 else 'Bearish'}
        Volatility: {'High' if abs(change_24h) > 5 else 'Moderate' if abs(change_24h) > 2 else 'Low'}
        """
        
        return description.strip()


class LongTermMemory:
    """
    é•¿æœŸè®°å¿†æœåŠ¡ï¼ˆQdrantå‘é‡æ•°æ®åº“ï¼‰
    å­˜å‚¨å†å²äº¤æ˜“ç»éªŒï¼Œç”¨äºç›¸ä¼¼åœºæ™¯æ£€ç´¢
    
    æ”¯æŒå¤šç§embeddingæœåŠ¡:
    - Qwen (æ¨è): æ€§ä»·æ¯”é«˜ï¼Œä¸­æ–‡æ”¯æŒå¥½
    - DeepSeek: ä½¿ç”¨ç‰¹å¾å“ˆå¸Œï¼Œæ— éœ€é¢å¤–è´¹ç”¨
    - OpenAI: æ•ˆæœå¥½ï¼Œä½†éœ€è¦é¢å¤–è´¹ç”¨
    """
    
    COLLECTION_NAME = "trading_memories"
    
    def __init__(
        self,
        qdrant_host: str = "localhost",
        qdrant_port: int = 6333,
        api_key: Optional[str] = None,
        embedding_provider: str = "auto"  # auto, qwen, deepseek, openai
    ):
        """
        åˆå§‹åŒ–é•¿æœŸè®°å¿†æœåŠ¡
        
        Args:
            qdrant_host: QdrantæœåŠ¡å™¨åœ°å€
            qdrant_port: Qdrantç«¯å£
            api_key: Embedding APIå¯†é’¥ï¼ˆå¦‚æœä¸ºNoneï¼Œè‡ªåŠ¨é€‰æ‹©ï¼‰
            embedding_provider: embeddingæœåŠ¡æä¾›å•†
        """
        self.client = QdrantClient(host=qdrant_host, port=qdrant_port)
        
        # åˆå§‹åŒ–å‘é‡åŒ–å™¨ï¼ˆè‡ªåŠ¨é€‰æ‹©providerï¼‰
        self.vectorizer = MarketStateVectorizer(
            api_key=api_key,
            provider=embedding_provider
        )
        
        # ä½¿ç”¨å‘é‡åŒ–å™¨çš„ç»´åº¦
        self.VECTOR_DIM = self.vectorizer.vector_dim
        
        # åˆå§‹åŒ–collection
        self._init_collection()
    
    def _init_collection(self):
        """åˆå§‹åŒ–Qdrant collection"""
        try:
            # æ£€æŸ¥collectionæ˜¯å¦å­˜åœ¨
            collections = self.client.get_collections().collections
            exists = any(c.name == self.COLLECTION_NAME for c in collections)
            
            if not exists:
                # ä½¿ç”¨å®é™…çš„å‘é‡ç»´åº¦åˆ›å»ºcollection
                self.client.create_collection(
                    collection_name=self.COLLECTION_NAME,
                    vectors_config=VectorParams(
                        size=self.VECTOR_DIM,
                        distance=Distance.COSINE
                    )
                )
                logger.info(f"åˆ›å»ºQdrant collection: {self.COLLECTION_NAME}")
            else:
                logger.info(f"Qdrant collectionå·²å­˜åœ¨: {self.COLLECTION_NAME}")
        
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–Qdrant collectionå¤±è´¥: {e}")
    
    async def store_decision(
        self,
        decision_id: str,
        timestamp: datetime,
        market_data: Dict[str, Any],
        decision: Dict[str, Any],
        result: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        å­˜å‚¨å†³ç­–åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            decision_id: å†³ç­–ID
            timestamp: æ—¶é—´æˆ³
            market_data: å¸‚åœºæ•°æ®
            decision: å†³ç­–å†…å®¹
            result: æ‰§è¡Œç»“æœï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # 1. å‘é‡åŒ–å¸‚åœºçŠ¶æ€
            vector = self.vectorizer.extract_features(market_data, decision)
            
            # 2. æ„å»ºpayload
            payload = {
                "decision_id": decision_id,
                "timestamp": timestamp.isoformat(),
                "symbol": decision.get("symbol", ""),
                "action": decision.get("action", ""),
                "size_usd": decision.get("size_usd", 0),
                "confidence": decision.get("confidence", 0),
                "reasoning": decision.get("reasoning", ""),
                "market_price": market_data.get(decision.get("symbol", ""), {}).get("price", 0),
                "market_change_24h": market_data.get(decision.get("symbol", ""), {}).get("change_24h", 0),
            }
            
            # 3. æ·»åŠ æ‰§è¡Œç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if result:
                payload.update({
                    "executed": True,
                    "pnl": result.get("pnl", 0),
                    "status": result.get("status", ""),
                })
            else:
                payload["executed"] = False
            
            # 4. ç”Ÿæˆå”¯ä¸€IDï¼ˆä½¿ç”¨decision_idçš„hashï¼‰
            point_id = int(hashlib.md5(decision_id.encode()).hexdigest()[:8], 16)
            
            # 5. æ’å…¥Qdrant
            self.client.upsert(
                collection_name=self.COLLECTION_NAME,
                points=[
                    PointStruct(
                        id=point_id,
                        vector=vector,
                        payload=payload
                    )
                ]
            )
            
            logger.info(f"å­˜å‚¨å†³ç­–åˆ°é•¿æœŸè®°å¿†: {decision_id}")
            return True
        
        except Exception as e:
            logger.error(f"å­˜å‚¨å†³ç­–åˆ°é•¿æœŸè®°å¿†å¤±è´¥: {e}")
            return False
    
    async def find_similar_situations(
        self,
        current_market_data: Dict[str, Any],
        current_decision: Dict[str, Any],
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼çš„å†å²åœºæ™¯
        
        Args:
            current_market_data: å½“å‰å¸‚åœºæ•°æ®
            current_decision: å½“å‰å†³ç­–
            limit: è¿”å›æ•°é‡
        
        Returns:
            ç›¸ä¼¼åœºæ™¯åˆ—è¡¨ï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰
        """
        try:
            # 1. å‘é‡åŒ–å½“å‰å¸‚åœºçŠ¶æ€
            query_vector = self.vectorizer.extract_features(
                current_market_data,
                current_decision
            )
            
            # 2. æœç´¢ç›¸ä¼¼å‘é‡
            search_result = self.client.search(
                collection_name=self.COLLECTION_NAME,
                query_vector=query_vector,
                limit=limit,
                with_payload=True
            )
            
            # 3. æ ¼å¼åŒ–ç»“æœ
            similar_situations = []
            for hit in search_result:
                similar_situations.append({
                    "score": hit.score,  # ç›¸ä¼¼åº¦åˆ†æ•°
                    "decision_id": hit.payload.get("decision_id"),
                    "timestamp": hit.payload.get("timestamp"),
                    "symbol": hit.payload.get("symbol"),
                    "action": hit.payload.get("action"),
                    "confidence": hit.payload.get("confidence"),
                    "reasoning": hit.payload.get("reasoning"),
                    "executed": hit.payload.get("executed"),
                    "pnl": hit.payload.get("pnl", 0),
                    "market_price": hit.payload.get("market_price"),
                    "market_change_24h": hit.payload.get("market_change_24h"),
                })
            
            logger.info(f"æ‰¾åˆ° {len(similar_situations)} ä¸ªç›¸ä¼¼åœºæ™¯")
            return similar_situations
        
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾ç›¸ä¼¼åœºæ™¯å¤±è´¥: {e}")
            return []
    
    async def get_pattern_statistics(
        self,
        symbol: str,
        action: str,
        days: int = 30
    ) -> Dict[str, Any]:
        """
        è·å–ç‰¹å®šäº¤æ˜“æ¨¡å¼çš„ç»Ÿè®¡æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹
            action: åŠ¨ä½œç±»å‹
            days: æ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰
        
        Returns:
            ç»Ÿè®¡æ•°æ®
        """
        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            cutoff_time = datetime.now() - timedelta(days=days)
            
            # ä½¿ç”¨scrollè·å–æ‰€æœ‰ç›¸å…³è®°å½•
            from qdrant_client.models import Filter, FieldCondition, MatchValue
            
            filter_condition = Filter(
                must=[
                    FieldCondition(
                        key="symbol",
                        match=MatchValue(value=symbol)
                    ),
                    FieldCondition(
                        key="action",
                        match=MatchValue(value=action)
                    ),
                ]
            )
            
            # æ»šåŠ¨æŸ¥è¯¢
            records, _ = self.client.scroll(
                collection_name=self.COLLECTION_NAME,
                scroll_filter=filter_condition,
                limit=1000
            )
            
            # è¿‡æ»¤æ—¶é—´èŒƒå›´
            recent_records = [
                r for r in records
                if datetime.fromisoformat(r.payload.get("timestamp", "1970-01-01")) > cutoff_time
            ]
            
            # ç»Ÿè®¡
            total_count = len(recent_records)
            executed_count = sum(1 for r in recent_records if r.payload.get("executed"))
            
            if executed_count == 0:
                return {
                    "symbol": symbol,
                    "action": action,
                    "total_count": total_count,
                    "executed_count": 0,
                    "success_rate": 0.0,
                    "avg_pnl": 0.0,
                }
            
            # è®¡ç®—æˆåŠŸç‡å’Œå¹³å‡PnL
            pnl_list = [r.payload.get("pnl", 0) for r in recent_records if r.payload.get("executed")]
            success_count = sum(1 for pnl in pnl_list if pnl > 0)
            
            return {
                "symbol": symbol,
                "action": action,
                "total_count": total_count,
                "executed_count": executed_count,
                "success_rate": success_count / executed_count if executed_count > 0 else 0.0,
                "avg_pnl": sum(pnl_list) / len(pnl_list) if pnl_list else 0.0,
                "total_pnl": sum(pnl_list),
            }
        
        except Exception as e:
            logger.error(f"è·å–æ¨¡å¼ç»Ÿè®¡å¤±è´¥: {e}")
            return {}


from datetime import timedelta

