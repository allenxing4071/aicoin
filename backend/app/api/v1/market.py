"""Market data API endpoints"""

from fastapi import APIRouter, HTTPException
from typing import List
from decimal import Decimal
import logging
import json

from app.schemas.market import KlineData, OrderbookData, TickerData
from app.services.market.hyperliquid_client import hyperliquid_client
from app.core.redis_client import redis_client

router = APIRouter()
logger = logging.getLogger(__name__)

# å¸‚åœºæ•°æ®ç¼“å­˜é…ç½®
TICKERS_CACHE_KEY = "market:tickers:all"
TICKERS_CACHE_TTL = 1  # ç¼“å­˜1ç§’ï¼Œé«˜é¢‘è°ƒç”¨ä¼˜åŒ–


def get_market_data_service():
    """è·å–å…¨å±€çš„market data service"""
    from app.main import market_data_service
    if market_data_service is None:
        logger.error("âŒ Market data service not initialized!")
        raise HTTPException(status_code=503, detail="Market data service not available")
    return market_data_service


@router.get("/klines", response_model=List[KlineData])
async def get_klines_query(
    symbol: str,
    interval: str = "1h",
    limit: int = 100
):
    """
    è·å–Kçº¿æ•°æ®ï¼ˆæŸ¥è¯¢å‚æ•°ç‰ˆæœ¬ï¼‰
    
    Args:
        symbol: äº¤æ˜“å“ç§ (å¦‚: BTCUSDT, BTC, ETH)
        interval: Kçº¿å‘¨æœŸ (1m, 5m, 1h, 4h, 1d)
        limit: è¿”å›æ•°é‡
        
    Returns:
        Kçº¿æ•°æ®åˆ—è¡¨
    """
    try:
        # å¤„ç†symbolæ ¼å¼ï¼šBTCUSDT -> BTC
        original_symbol = symbol
        if symbol.endswith('USDT'):
            symbol = symbol[:-4]
        
        service = get_market_data_service()
        klines = await service.get_klines(symbol, interval, limit)
        
        # è½¬æ¢æ•°æ®æ ¼å¼ä»¥åŒ¹é…KlineData schema
        from datetime import datetime, timedelta
        result = []
        for k in klines:
            # è®¡ç®—close_timeï¼ˆå‡è®¾æ˜¯open_time + intervalï¼‰
            # æ³¨æ„ï¼štimestampå¯èƒ½æ˜¯ç§’æˆ–æ¯«ç§’ï¼Œéœ€è¦åˆ¤æ–­
            timestamp = k.get('timestamp', 0)
            if timestamp > 10000000000:  # å¦‚æœå¤§äºè¿™ä¸ªå€¼ï¼Œè¯´æ˜æ˜¯æ¯«ç§’
                timestamp = timestamp / 1000
            open_time = datetime.fromtimestamp(timestamp)
            
            # æ ¹æ®intervalè®¡ç®—close_time
            interval_seconds = {
                '1m': 60,
                '5m': 300,
                '15m': 900,
                '1h': 3600,
                '4h': 14400,
                '1d': 86400
            }.get(interval, 3600)
            close_time = open_time + timedelta(seconds=interval_seconds)
            
            result.append(KlineData(
                symbol=original_symbol,
                interval=interval,
                open_time=open_time,
                close_time=close_time,
                open=k.get('open', 0),
                high=k.get('high', 0),
                low=k.get('low', 0),
                close=k.get('close', 0),
                volume=k.get('volume', 0)
            ))
        
        return result
        
    except Exception as e:
        logger.error(f"Error fetching klines for {symbol}: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/kline/{symbol}", response_model=List[KlineData])
async def get_kline(
    symbol: str,
    interval: str = "1h",
    limit: int = 100
):
    """
    è·å–Kçº¿æ•°æ®ï¼ˆè·¯å¾„å‚æ•°ç‰ˆæœ¬ï¼‰
    
    Args:
        symbol: äº¤æ˜“å“ç§
        interval: Kçº¿å‘¨æœŸ (1m, 5m, 1h, 4h, 1d)
        limit: è¿”å›æ•°é‡
        
    Returns:
        Kçº¿æ•°æ®åˆ—è¡¨
    """
    try:
        service = get_market_data_service()
        klines = await service.get_klines(symbol, interval, limit)
        return [KlineData(**k) for k in klines]
        
    except Exception as e:
        logger.error(f"Error fetching klines: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/orderbook/{symbol}", response_model=OrderbookData)
async def get_orderbook(
    symbol: str,
    depth: int = 20
):
    """
    è·å–è®¢å•ç°¿
    
    Args:
        symbol: äº¤æ˜“å“ç§
        depth: æ·±åº¦æ¡£ä½
        
    Returns:
        è®¢å•ç°¿æ•°æ®
    """
    try:
        service = get_market_data_service()
        orderbook = await service.get_orderbook(symbol, depth)
        return OrderbookData(**orderbook)
        
    except Exception as e:
        logger.error(f"Error fetching orderbook: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/ticker/{symbol}", response_model=TickerData)
async def get_ticker(symbol: str):
    """
    è·å–å®æ—¶ä»·æ ¼
    
    Args:
        symbol: äº¤æ˜“å“ç§
        
    Returns:
        å®æ—¶ä»·æ ¼æ•°æ®
    """
    try:
        service = get_market_data_service()
        ticker = await service.get_ticker(symbol)
        return TickerData(**ticker)
        
    except Exception as e:
        logger.error(f"Error fetching ticker: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/tickers", response_model=List[TickerData])
async def get_all_tickers(force_refresh: bool = False):
    """
    è·å–æ‰€æœ‰äº¤æ˜“å¯¹çš„å®æ—¶ä»·æ ¼ï¼ˆå¸¦Redisç¼“å­˜ä¼˜åŒ–ï¼‰
    
    Args:
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    
    Returns:
        æ‰€æœ‰äº¤æ˜“å¯¹çš„å®æ—¶ä»·æ ¼åˆ—è¡¨
    """
    try:
        # 1. å°è¯•ä»ç¼“å­˜è·å–ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if not force_refresh:
            try:
                cached_data = await redis_client.get(TICKERS_CACHE_KEY)
                if cached_data:
                    logger.debug(f"âœ… è¡Œæƒ…æ•°æ®å‘½ä¸­ç¼“å­˜")
                    return [TickerData(**t) for t in cached_data]
            except Exception as cache_err:
                logger.warning(f"ç¼“å­˜è¯»å–å¤±è´¥: {cache_err}")
        
        # 2. ä»å¸‚åœºæœåŠ¡è·å–æœ€æ–°æ•°æ®
        symbols = ["BTC", "ETH", "SOL", "BNB", "DOGE", "XRP"]
        service = get_market_data_service()
        tickers = []
        
        for symbol in symbols:
            try:
                ticker = await service.get_ticker(symbol)
                tickers.append(TickerData(**ticker))
            except Exception as e:
                logger.warning(f"Error fetching ticker for {symbol}: {e}")
                continue
        
        # 3. å†™å…¥ç¼“å­˜
        if tickers:
            try:
                await redis_client.set(
                    TICKERS_CACHE_KEY,
                    [t.dict() for t in tickers],
                    expire=TICKERS_CACHE_TTL
                )
                logger.debug(f"ğŸ’¾ è¡Œæƒ…æ•°æ®å·²ç¼“å­˜ {TICKERS_CACHE_TTL}ç§’")
            except Exception as cache_err:
                logger.warning(f"ç¼“å­˜å†™å…¥å¤±è´¥: {cache_err}")
        
        return tickers
        
    except Exception as e:
        logger.error(f"Error fetching all tickers: {e}")
        raise HTTPException(status_code=500, detail=str(e))

