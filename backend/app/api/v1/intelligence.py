"""Intelligence Report API Endpoints"""

import logging
from datetime import datetime, timedelta
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import func, desc

from app.core.database import get_db
from app.models.intelligence import IntelligenceReport
from app.services.intelligence.storage import intelligence_storage

logger = logging.getLogger(__name__)

router = APIRouter()


@router.get("/latest")
async def get_latest_intelligence():
    """è·å–æœ€æ–°æƒ…æŠ¥ï¼ˆå¿«æ·è·¯å¾„ï¼‰"""
    try:
        report = await intelligence_storage.get_latest_report()
        if not report:
            raise HTTPException(status_code=404, detail="æš‚æ— æœ€æ–°æƒ…æŠ¥æŠ¥å‘Š")
        
        return {
            "success": True,
            "data": report.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æœ€æ–°æƒ…æŠ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/refresh")
async def refresh_intelligence(db: AsyncSession = Depends(get_db)):
    """æ‰‹åŠ¨è§¦å‘æƒ…æŠ¥æ”¶é›†ï¼ˆä½¿ç”¨æ–°çš„IntelligenceCoordinatorï¼‰"""
    try:
        # ä½¿ç”¨æ–°çš„ç»Ÿä¸€åè°ƒå™¨
        from app.services.intelligence.intelligence_coordinator import IntelligenceCoordinator
        from app.core.redis_client import redis_client
        
        logger.info("ğŸ”„ æ‰‹åŠ¨è§¦å‘æƒ…æŠ¥æ”¶é›†ï¼ˆä½¿ç”¨IntelligenceCoordinatorï¼‰...")
        
        # åˆ›å»ºåè°ƒå™¨å¹¶æ‰§è¡Œæ”¶é›†
        coordinator = IntelligenceCoordinator(redis_client, db)
        report = await coordinator.collect_intelligence()
        
        if not report:
            raise HTTPException(status_code=500, detail="æƒ…æŠ¥æ”¶é›†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
        
        return {
            "success": True,
            "message": "æƒ…æŠ¥æ”¶é›†æˆåŠŸï¼ˆå¤šå¹³å°éªŒè¯+å››å±‚å­˜å‚¨ï¼‰",
            "data": report.to_dict()
        }
    
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨æ”¶é›†æƒ…æŠ¥å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/reports")
async def get_reports(
    limit: int = Query(default=20, ge=1, le=100, description="è¿”å›è®°å½•æ•°é‡"),
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–æƒ…æŠ¥æŠ¥å‘Šåˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    ç”¨äºå‰ç«¯é¡µé¢å¿«é€Ÿè·å–æœ€æ–°æŠ¥å‘Š
    """
    try:
        from sqlalchemy import select
        # æŸ¥è¯¢æœ€æ–°çš„æŠ¥å‘Š
        stmt = select(IntelligenceReport)\
                .order_by(desc(IntelligenceReport.timestamp))\
                .limit(limit)
        result = await db.execute(stmt)
        reports = result.scalars().all()
        
        return {
            "success": True,
            "data": [r.to_dict() for r in reports],
            "total": len(reports)
        }
    
    except Exception as e:
        logger.error(f"è·å–æƒ…æŠ¥æŠ¥å‘Šå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/reports/latest")
async def get_latest_report():
    """è·å–æœ€æ–°çš„æƒ…æŠ¥æŠ¥å‘Šï¼ˆæ¥è‡ªRedisç¼“å­˜ï¼‰"""
    try:
        report = await intelligence_storage.get_latest_report()
        if not report:
            raise HTTPException(status_code=404, detail="æš‚æ— æœ€æ–°æƒ…æŠ¥æŠ¥å‘Š")
        
        return {
            "success": True,
            "data": report.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æœ€æ–°æƒ…æŠ¥æŠ¥å‘Šå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/reports/history")
async def get_report_history(
    limit: int = Query(default=10, ge=1, le=100, description="è¿”å›è®°å½•æ•°é‡"),
    offset: int = Query(default=0, ge=0, description="åç§»é‡"),
    start_date: Optional[datetime] = Query(default=None, description="èµ·å§‹æ—¶é—´"),
    end_date: Optional[datetime] = Query(default=None, description="ç»“æŸæ—¶é—´"),
    sentiment: Optional[str] = Query(default=None, description="æƒ…ç»ªç±»å‹: BULLISH/BEARISH/NEUTRAL"),
    min_confidence: Optional[float] = Query(default=None, ge=0.0, le=1.0, description="æœ€å°ç½®ä¿¡åº¦"),
    db: Session = Depends(get_db)
):
    """
    è·å–å†å²æƒ…æŠ¥æŠ¥å‘Šï¼ˆæ¥è‡ªPostgreSQLæŒä¹…åŒ–å­˜å‚¨ï¼‰
    
    æ”¯æŒå¤šç§ç­›é€‰æ¡ä»¶ï¼š
    - æ—¶é—´èŒƒå›´
    - æƒ…ç»ªç±»å‹
    - æœ€å°ç½®ä¿¡åº¦
    """
    try:
        # æ„å»ºæŸ¥è¯¢
        query = db.query(IntelligenceReport)
        
        # æ—¶é—´èŒƒå›´ç­›é€‰
        if start_date:
            query = query.filter(IntelligenceReport.timestamp >= start_date)
        if end_date:
            query = query.filter(IntelligenceReport.timestamp <= end_date)
        
        # æƒ…ç»ªç±»å‹ç­›é€‰
        if sentiment:
            query = query.filter(IntelligenceReport.market_sentiment == sentiment.upper())
        
        # ç½®ä¿¡åº¦ç­›é€‰
        if min_confidence is not None:
            query = query.filter(IntelligenceReport.confidence >= min_confidence)
        
        # æ’åºå’Œåˆ†é¡µ
        total = query.count()
        reports = query.order_by(desc(IntelligenceReport.timestamp))\
                      .offset(offset)\
                      .limit(limit)\
                      .all()
        
        return {
            "success": True,
            "data": {
                "total": total,
                "limit": limit,
                "offset": offset,
                "reports": [r.to_dict() for r in reports]
            }
        }
    
    except Exception as e:
        logger.error(f"è·å–å†å²æƒ…æŠ¥æŠ¥å‘Šå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/reports/{report_id}")
async def get_report_by_id(
    report_id: int,
    db: Session = Depends(get_db)
):
    """æ ¹æ®IDè·å–ç‰¹å®šæƒ…æŠ¥æŠ¥å‘Š"""
    try:
        report = db.query(IntelligenceReport).filter(
            IntelligenceReport.id == report_id
        ).first()
        
        if not report:
            raise HTTPException(status_code=404, detail=f"æƒ…æŠ¥æŠ¥å‘Šä¸å­˜åœ¨: ID={report_id}")
        
        return {
            "success": True,
            "data": report.to_dict()
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æƒ…æŠ¥æŠ¥å‘Šå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analytics/summary")
async def get_analytics_summary(
    days: int = Query(default=7, ge=1, le=90, description="ç»Ÿè®¡å¤©æ•°"),
    db: Session = Depends(get_db)
):
    """
    è·å–æƒ…æŠ¥åˆ†æç»Ÿè®¡æ‘˜è¦
    
    åŒ…æ‹¬ï¼š
    - æ€»æŠ¥å‘Šæ•°
    - æƒ…ç»ªåˆ†å¸ƒ
    - å¹³å‡ç½®ä¿¡åº¦
    - è¶‹åŠ¿åˆ†æ
    """
    try:
        start_date = datetime.now() - timedelta(days=days)
        
        # åŸºç¡€ç»Ÿè®¡
        total_reports = db.query(func.count(IntelligenceReport.id))\
            .filter(IntelligenceReport.timestamp >= start_date)\
            .scalar()
        
        # æƒ…ç»ªåˆ†å¸ƒ
        sentiment_stats = db.query(
            IntelligenceReport.market_sentiment,
            func.count(IntelligenceReport.id).label('count')
        ).filter(
            IntelligenceReport.timestamp >= start_date
        ).group_by(
            IntelligenceReport.market_sentiment
        ).all()
        
        sentiment_distribution = {
            s[0]: s[1] for s in sentiment_stats
        }
        
        # å¹³å‡ç½®ä¿¡åº¦
        avg_confidence = db.query(
            func.avg(IntelligenceReport.confidence)
        ).filter(
            IntelligenceReport.timestamp >= start_date
        ).scalar()
        
        # æ¯æ—¥æŠ¥å‘Šæ•°
        daily_reports = db.query(
            func.date(IntelligenceReport.timestamp).label('date'),
            func.count(IntelligenceReport.id).label('count')
        ).filter(
            IntelligenceReport.timestamp >= start_date
        ).group_by(
            func.date(IntelligenceReport.timestamp)
        ).order_by(
            desc('date')
        ).all()
        
        return {
            "success": True,
            "data": {
                "period_days": days,
                "start_date": start_date.isoformat(),
                "end_date": datetime.now().isoformat(),
                "total_reports": total_reports or 0,
                "sentiment_distribution": sentiment_distribution,
                "average_confidence": float(avg_confidence) if avg_confidence else 0.0,
                "daily_reports": [
                    {
                        "date": str(d[0]),
                        "count": d[1]
                    }
                    for d in daily_reports
                ]
            }
        }
    
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡æ‘˜è¦å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analytics/sentiment-trend")
async def get_sentiment_trend(
    days: int = Query(default=30, ge=1, le=90, description="ç»Ÿè®¡å¤©æ•°"),
    db: Session = Depends(get_db)
):
    """
    è·å–å¸‚åœºæƒ…ç»ªè¶‹åŠ¿
    
    è¿”å›æ¯æ—¥çš„æƒ…ç»ªåˆ†å¸ƒï¼Œç”¨äºè¶‹åŠ¿åˆ†æ
    """
    try:
        start_date = datetime.now() - timedelta(days=days)
        
        # æŸ¥è¯¢æ¯æ—¥å„æƒ…ç»ªçš„æ•°é‡
        trend_data = db.query(
            func.date(IntelligenceReport.timestamp).label('date'),
            IntelligenceReport.market_sentiment,
            func.count(IntelligenceReport.id).label('count'),
            func.avg(IntelligenceReport.sentiment_score).label('avg_score')
        ).filter(
            IntelligenceReport.timestamp >= start_date
        ).group_by(
            func.date(IntelligenceReport.timestamp),
            IntelligenceReport.market_sentiment
        ).order_by(
            'date'
        ).all()
        
        # ç»„ç»‡æ•°æ®
        daily_data = {}
        for row in trend_data:
            date_str = str(row[0])
            if date_str not in daily_data:
                daily_data[date_str] = {
                    "date": date_str,
                    "sentiments": {},
                    "scores": {}
                }
            daily_data[date_str]["sentiments"][row[1]] = row[2]
            daily_data[date_str]["scores"][row[1]] = float(row[3]) if row[3] else 0.0
        
        return {
            "success": True,
            "data": {
                "period_days": days,
                "trend": list(daily_data.values())
            }
        }
    
    except Exception as e:
        logger.error(f"è·å–æƒ…ç»ªè¶‹åŠ¿å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analytics/data-quality")
async def get_data_quality_stats(
    days: int = Query(default=7, ge=1, le=30, description="ç»Ÿè®¡å¤©æ•°"),
    db: Session = Depends(get_db)
):
    """
    è·å–æ•°æ®è´¨é‡ç»Ÿè®¡
    
    åŒ…æ‹¬ï¼š
    - å„æ•°æ®æºçš„è¦†ç›–ç‡
    - ç½®ä¿¡åº¦åˆ†å¸ƒ
    - æ•°æ®å®Œæ•´æ€§
    """
    try:
        start_date = datetime.now() - timedelta(days=days)
        
        reports = db.query(IntelligenceReport).filter(
            IntelligenceReport.timestamp >= start_date
        ).all()
        
        if not reports:
            return {
                "success": True,
                "data": {
                    "period_days": days,
                    "total_reports": 0,
                    "data_coverage": {},
                    "confidence_distribution": {},
                    "completeness": 0.0
                }
            }
        
        # æ•°æ®è¦†ç›–ç‡
        coverage = {
            "news": sum(1 for r in reports if r.key_news and len(r.key_news) > 0),
            "whale": sum(1 for r in reports if r.whale_signals and len(r.whale_signals) > 0),
            "onchain": sum(1 for r in reports if r.on_chain_metrics),
        }
        
        # ç½®ä¿¡åº¦åˆ†å¸ƒ
        confidence_ranges = {
            "0.0-0.3": 0,
            "0.3-0.5": 0,
            "0.5-0.7": 0,
            "0.7-0.9": 0,
            "0.9-1.0": 0
        }
        
        for r in reports:
            conf = r.confidence
            if conf < 0.3:
                confidence_ranges["0.0-0.3"] += 1
            elif conf < 0.5:
                confidence_ranges["0.3-0.5"] += 1
            elif conf < 0.7:
                confidence_ranges["0.5-0.7"] += 1
            elif conf < 0.9:
                confidence_ranges["0.7-0.9"] += 1
            else:
                confidence_ranges["0.9-1.0"] += 1
        
        # å®Œæ•´æ€§è¯„åˆ†ï¼ˆæœ‰åˆ†ææ–‡æœ¬çš„æ¯”ä¾‹ï¼‰
        complete_reports = sum(
            1 for r in reports 
            if r.qwen_analysis and len(r.qwen_analysis) > 0
        )
        completeness = complete_reports / len(reports) if reports else 0.0
        
        return {
            "success": True,
            "data": {
                "period_days": days,
                "total_reports": len(reports),
                "data_coverage": {
                    "news_coverage": coverage["news"] / len(reports),
                    "whale_coverage": coverage["whale"] / len(reports),
                    "onchain_coverage": coverage["onchain"] / len(reports),
                },
                "confidence_distribution": confidence_ranges,
                "completeness_score": completeness
            }
        }
    
    except Exception as e:
        logger.error(f"è·å–æ•°æ®è´¨é‡ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/debated-report")
async def get_debated_intelligence_report(db: AsyncSession = Depends(get_db)):
    """
    è·å–ç»è¿‡è¾©è®ºéªŒè¯çš„æƒ…æŠ¥æŠ¥å‘Š
    
    æµç¨‹ï¼š
    1. è·å–æœ€æ–°çš„ Qwen æƒ…æŠ¥
    2. è§¦å‘å¤šç©ºè¾©è®ºç³»ç»Ÿï¼ˆBull vs Bearï¼‰
    3. ç ”ç©¶ç»ç†ç»¼åˆåˆ¤æ–­
    4. è¿”å›è¾©è®ºåçš„ç»¼åˆæŠ¥å‘Š
    """
    try:
        from app.services.decision.debate_system import DebateCoordinator
        from app.services.decision.prompt_manager_db import PromptManagerDB
        from app.core.redis_client import redis_client
        import openai
        from app.core.config import settings
        
        logger.info("ğŸ”„ å¼€å§‹ç”Ÿæˆè¾©è®ºåçš„æƒ…æŠ¥æŠ¥å‘Š...")
        
        # 1. è·å–æœ€æ–°çš„ Qwen æƒ…æŠ¥
        report = await intelligence_storage.get_latest_report()
        if not report:
            raise HTTPException(status_code=404, detail="æš‚æ— æœ€æ–°æƒ…æŠ¥æŠ¥å‘Š")
        
        logger.info(f"ğŸ“Š è·å–åˆ° Qwen æƒ…æŠ¥: æƒ…ç»ª={report.market_sentiment}, ç½®ä¿¡åº¦={report.confidence:.2%}")
        
        # 2. å‡†å¤‡å¸‚åœºæ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºè¾©è®ºï¼‰
        market_data = {
            "BTC": {
                "price": 95000,  # å¯ä»¥ä»å®é™…å¸‚åœºæ•°æ®è·å–
                "change_24h": 2.5
            }
        }
        
        # 3. å‡†å¤‡æƒ…æŠ¥å­—å…¸
        intelligence_dict = {
            "market_sentiment": report.market_sentiment.value if hasattr(report.market_sentiment, 'value') else str(report.market_sentiment),
            "confidence": report.confidence,
            "summary": report.summary[:500] if report.summary else "",
            "key_news": report.key_news[:3] if report.key_news else [],
            "whale_signals": report.whale_signals[:3] if report.whale_signals else [],
            "platform_contributions": getattr(report, 'platform_contributions', {}),
            "platform_consensus": getattr(report, 'platform_consensus', 0.0),
        }
        
        # 4. åˆå§‹åŒ–è¾©è®ºç³»ç»Ÿ
        llm_client = openai.OpenAI(
            api_key=settings.DEEPSEEK_API_KEY,
            base_url="https://api.deepseek.com/v1"
        )
        
        prompt_manager = PromptManagerDB(db)
        
        debate_coordinator = DebateCoordinator(
            llm_client=llm_client,
            max_debate_rounds=1,  # 1è½®è¾©è®º
            timeout_seconds=60,
            prompt_manager=prompt_manager
        )
        
        # 5. æ‰§è¡Œè¾©è®º
        logger.info("âš”ï¸  å¯åŠ¨å¤šç©ºè¾©è®º...")
        debate_result = await debate_coordinator.conduct_debate(
            market_data=market_data,
            intelligence_report=intelligence_dict,
            past_memories=[]
        )
        
        logger.info(f"âœ… è¾©è®ºå®Œæˆ: æ¨è={debate_result['final_decision'].get('recommendation')}, "
                   f"å…±è¯†åº¦={debate_result['consensus_level']:.2f}")
        
        # 6. æ„å»ºè¿”å›æ•°æ®
        return {
            "success": True,
            "data": {
                # åŸå§‹ Qwen æƒ…æŠ¥
                "original_intelligence": {
                    "market_sentiment": intelligence_dict["market_sentiment"],
                    "confidence": intelligence_dict["confidence"],
                    "summary": intelligence_dict["summary"],
                    "key_news": intelligence_dict["key_news"],
                    "whale_signals": intelligence_dict["whale_signals"],
                    "timestamp": report.timestamp.isoformat() if report.timestamp else None
                },
                # è¾©è®ºç»“æœ
                "debate_result": {
                    "recommendation": debate_result['final_decision'].get('recommendation', 'HOLD'),
                    "confidence": debate_result['final_decision'].get('confidence', 0.5),
                    "reasoning": debate_result['final_decision'].get('reasoning', ''),
                    "bull_argument": debate_result['debate_history'].get('bull_arguments', []),
                    "bear_argument": debate_result['debate_history'].get('bear_arguments', []),
                    "consensus_level": debate_result['consensus_level'],
                    "total_rounds": debate_result['total_rounds'],
                    "duration_seconds": debate_result['duration_seconds']
                },
                # ç»¼åˆåˆ†æ
                "enhanced_sentiment": debate_result['final_decision'].get('recommendation', 'HOLD'),
                "enhanced_confidence": debate_result['final_decision'].get('confidence', 0.5),
                "is_debated": True
            }
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç”Ÿæˆè¾©è®ºåæƒ…æŠ¥å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è¾©è®ºå¤±è´¥: {str(e)}")


@router.post("/trigger-debate")
async def trigger_debate_manually(db: AsyncSession = Depends(get_db)):
    """
    æ‰‹åŠ¨è§¦å‘æƒ…æŠ¥è¾©è®º
    
    ç”¨æˆ·å¯ä»¥ç‚¹å‡»æŒ‰é’®æ‰‹åŠ¨è§¦å‘æ–°ä¸€è½®è¾©è®º
    """
    try:
        # å¤ç”¨ get_debated_intelligence_report çš„é€»è¾‘
        result = await get_debated_intelligence_report(db)
        
        return {
            "success": True,
            "message": "è¾©è®ºå·²å®Œæˆ",
            "data": result["data"]
        }
    
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨è§¦å‘è¾©è®ºå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
