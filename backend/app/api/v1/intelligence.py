"""Intelligence Report API Endpoints"""

import logging
from datetime import datetime, timedelta
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from sqlalchemy import func, desc

from app.core.database import get_db
from app.models.intelligence import IntelligenceReport
from app.services.intelligence.storage import intelligence_storage

logger = logging.getLogger(__name__)

router = APIRouter()


@router.get("/latest")
async def get_latest_intelligence():
    """è·å–æœ€æ–°æƒ…æŠ¥ï¼ˆå¿«æ·è·¯å¾„ï¼‰"""
    try:
        report = await intelligence_storage.get_latest_report()
        if not report:
            raise HTTPException(status_code=404, detail="æš‚æ— æœ€æ–°æƒ…æŠ¥æŠ¥å‘Š")
        
        return {
            "success": True,
            "data": report.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æœ€æ–°æƒ…æŠ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/refresh")
async def refresh_intelligence():
    """æ‰‹åŠ¨è§¦å‘æƒ…æŠ¥æ”¶é›†"""
    try:
        # å¯¼å…¥å¹¶è°ƒç”¨æƒ…æŠ¥æ”¶é›†æœåŠ¡
        from app.services.intelligence.qwen_engine import qwen_intelligence_officer
        
        logger.info("ğŸ”„ æ‰‹åŠ¨è§¦å‘æƒ…æŠ¥æ”¶é›†...")
        
        # æ‰§è¡Œæƒ…æŠ¥æ”¶é›†
        report = await qwen_intelligence_officer.collect_intelligence()
        
        if not report:
            raise HTTPException(status_code=500, detail="æƒ…æŠ¥æ”¶é›†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
        
        return {
            "success": True,
            "message": "æƒ…æŠ¥æ”¶é›†æˆåŠŸ",
            "data": report.to_dict()
        }
    
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨æ”¶é›†æƒ…æŠ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/reports/latest")
async def get_latest_report():
    """è·å–æœ€æ–°çš„æƒ…æŠ¥æŠ¥å‘Šï¼ˆæ¥è‡ªRedisç¼“å­˜ï¼‰"""
    try:
        report = await intelligence_storage.get_latest_report()
        if not report:
            raise HTTPException(status_code=404, detail="æš‚æ— æœ€æ–°æƒ…æŠ¥æŠ¥å‘Š")
        
        return {
            "success": True,
            "data": report.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æœ€æ–°æƒ…æŠ¥æŠ¥å‘Šå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/reports/history")
async def get_report_history(
    limit: int = Query(default=10, ge=1, le=100, description="è¿”å›è®°å½•æ•°é‡"),
    offset: int = Query(default=0, ge=0, description="åç§»é‡"),
    start_date: Optional[datetime] = Query(default=None, description="èµ·å§‹æ—¶é—´"),
    end_date: Optional[datetime] = Query(default=None, description="ç»“æŸæ—¶é—´"),
    sentiment: Optional[str] = Query(default=None, description="æƒ…ç»ªç±»å‹: BULLISH/BEARISH/NEUTRAL"),
    min_confidence: Optional[float] = Query(default=None, ge=0.0, le=1.0, description="æœ€å°ç½®ä¿¡åº¦"),
    db: Session = Depends(get_db)
):
    """
    è·å–å†å²æƒ…æŠ¥æŠ¥å‘Šï¼ˆæ¥è‡ªPostgreSQLæŒä¹…åŒ–å­˜å‚¨ï¼‰
    
    æ”¯æŒå¤šç§ç­›é€‰æ¡ä»¶ï¼š
    - æ—¶é—´èŒƒå›´
    - æƒ…ç»ªç±»å‹
    - æœ€å°ç½®ä¿¡åº¦
    """
    try:
        # æ„å»ºæŸ¥è¯¢
        query = db.query(IntelligenceReport)
        
        # æ—¶é—´èŒƒå›´ç­›é€‰
        if start_date:
            query = query.filter(IntelligenceReport.timestamp >= start_date)
        if end_date:
            query = query.filter(IntelligenceReport.timestamp <= end_date)
        
        # æƒ…ç»ªç±»å‹ç­›é€‰
        if sentiment:
            query = query.filter(IntelligenceReport.market_sentiment == sentiment.upper())
        
        # ç½®ä¿¡åº¦ç­›é€‰
        if min_confidence is not None:
            query = query.filter(IntelligenceReport.confidence >= min_confidence)
        
        # æ’åºå’Œåˆ†é¡µ
        total = query.count()
        reports = query.order_by(desc(IntelligenceReport.timestamp))\
                      .offset(offset)\
                      .limit(limit)\
                      .all()
        
        return {
            "success": True,
            "data": {
                "total": total,
                "limit": limit,
                "offset": offset,
                "reports": [r.to_dict() for r in reports]
            }
        }
    
    except Exception as e:
        logger.error(f"è·å–å†å²æƒ…æŠ¥æŠ¥å‘Šå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/reports/{report_id}")
async def get_report_by_id(
    report_id: int,
    db: Session = Depends(get_db)
):
    """æ ¹æ®IDè·å–ç‰¹å®šæƒ…æŠ¥æŠ¥å‘Š"""
    try:
        report = db.query(IntelligenceReport).filter(
            IntelligenceReport.id == report_id
        ).first()
        
        if not report:
            raise HTTPException(status_code=404, detail=f"æƒ…æŠ¥æŠ¥å‘Šä¸å­˜åœ¨: ID={report_id}")
        
        return {
            "success": True,
            "data": report.to_dict()
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æƒ…æŠ¥æŠ¥å‘Šå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analytics/summary")
async def get_analytics_summary(
    days: int = Query(default=7, ge=1, le=90, description="ç»Ÿè®¡å¤©æ•°"),
    db: Session = Depends(get_db)
):
    """
    è·å–æƒ…æŠ¥åˆ†æç»Ÿè®¡æ‘˜è¦
    
    åŒ…æ‹¬ï¼š
    - æ€»æŠ¥å‘Šæ•°
    - æƒ…ç»ªåˆ†å¸ƒ
    - å¹³å‡ç½®ä¿¡åº¦
    - è¶‹åŠ¿åˆ†æ
    """
    try:
        start_date = datetime.now() - timedelta(days=days)
        
        # åŸºç¡€ç»Ÿè®¡
        total_reports = db.query(func.count(IntelligenceReport.id))\
            .filter(IntelligenceReport.timestamp >= start_date)\
            .scalar()
        
        # æƒ…ç»ªåˆ†å¸ƒ
        sentiment_stats = db.query(
            IntelligenceReport.market_sentiment,
            func.count(IntelligenceReport.id).label('count')
        ).filter(
            IntelligenceReport.timestamp >= start_date
        ).group_by(
            IntelligenceReport.market_sentiment
        ).all()
        
        sentiment_distribution = {
            s[0]: s[1] for s in sentiment_stats
        }
        
        # å¹³å‡ç½®ä¿¡åº¦
        avg_confidence = db.query(
            func.avg(IntelligenceReport.confidence)
        ).filter(
            IntelligenceReport.timestamp >= start_date
        ).scalar()
        
        # æ¯æ—¥æŠ¥å‘Šæ•°
        daily_reports = db.query(
            func.date(IntelligenceReport.timestamp).label('date'),
            func.count(IntelligenceReport.id).label('count')
        ).filter(
            IntelligenceReport.timestamp >= start_date
        ).group_by(
            func.date(IntelligenceReport.timestamp)
        ).order_by(
            desc('date')
        ).all()
        
        return {
            "success": True,
            "data": {
                "period_days": days,
                "start_date": start_date.isoformat(),
                "end_date": datetime.now().isoformat(),
                "total_reports": total_reports or 0,
                "sentiment_distribution": sentiment_distribution,
                "average_confidence": float(avg_confidence) if avg_confidence else 0.0,
                "daily_reports": [
                    {
                        "date": str(d[0]),
                        "count": d[1]
                    }
                    for d in daily_reports
                ]
            }
        }
    
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡æ‘˜è¦å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analytics/sentiment-trend")
async def get_sentiment_trend(
    days: int = Query(default=30, ge=1, le=90, description="ç»Ÿè®¡å¤©æ•°"),
    db: Session = Depends(get_db)
):
    """
    è·å–å¸‚åœºæƒ…ç»ªè¶‹åŠ¿
    
    è¿”å›æ¯æ—¥çš„æƒ…ç»ªåˆ†å¸ƒï¼Œç”¨äºè¶‹åŠ¿åˆ†æ
    """
    try:
        start_date = datetime.now() - timedelta(days=days)
        
        # æŸ¥è¯¢æ¯æ—¥å„æƒ…ç»ªçš„æ•°é‡
        trend_data = db.query(
            func.date(IntelligenceReport.timestamp).label('date'),
            IntelligenceReport.market_sentiment,
            func.count(IntelligenceReport.id).label('count'),
            func.avg(IntelligenceReport.sentiment_score).label('avg_score')
        ).filter(
            IntelligenceReport.timestamp >= start_date
        ).group_by(
            func.date(IntelligenceReport.timestamp),
            IntelligenceReport.market_sentiment
        ).order_by(
            'date'
        ).all()
        
        # ç»„ç»‡æ•°æ®
        daily_data = {}
        for row in trend_data:
            date_str = str(row[0])
            if date_str not in daily_data:
                daily_data[date_str] = {
                    "date": date_str,
                    "sentiments": {},
                    "scores": {}
                }
            daily_data[date_str]["sentiments"][row[1]] = row[2]
            daily_data[date_str]["scores"][row[1]] = float(row[3]) if row[3] else 0.0
        
        return {
            "success": True,
            "data": {
                "period_days": days,
                "trend": list(daily_data.values())
            }
        }
    
    except Exception as e:
        logger.error(f"è·å–æƒ…ç»ªè¶‹åŠ¿å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analytics/data-quality")
async def get_data_quality_stats(
    days: int = Query(default=7, ge=1, le=30, description="ç»Ÿè®¡å¤©æ•°"),
    db: Session = Depends(get_db)
):
    """
    è·å–æ•°æ®è´¨é‡ç»Ÿè®¡
    
    åŒ…æ‹¬ï¼š
    - å„æ•°æ®æºçš„è¦†ç›–ç‡
    - ç½®ä¿¡åº¦åˆ†å¸ƒ
    - æ•°æ®å®Œæ•´æ€§
    """
    try:
        start_date = datetime.now() - timedelta(days=days)
        
        reports = db.query(IntelligenceReport).filter(
            IntelligenceReport.timestamp >= start_date
        ).all()
        
        if not reports:
            return {
                "success": True,
                "data": {
                    "period_days": days,
                    "total_reports": 0,
                    "data_coverage": {},
                    "confidence_distribution": {},
                    "completeness": 0.0
                }
            }
        
        # æ•°æ®è¦†ç›–ç‡
        coverage = {
            "news": sum(1 for r in reports if r.key_news and len(r.key_news) > 0),
            "whale": sum(1 for r in reports if r.whale_signals and len(r.whale_signals) > 0),
            "onchain": sum(1 for r in reports if r.on_chain_metrics),
        }
        
        # ç½®ä¿¡åº¦åˆ†å¸ƒ
        confidence_ranges = {
            "0.0-0.3": 0,
            "0.3-0.5": 0,
            "0.5-0.7": 0,
            "0.7-0.9": 0,
            "0.9-1.0": 0
        }
        
        for r in reports:
            conf = r.confidence
            if conf < 0.3:
                confidence_ranges["0.0-0.3"] += 1
            elif conf < 0.5:
                confidence_ranges["0.3-0.5"] += 1
            elif conf < 0.7:
                confidence_ranges["0.5-0.7"] += 1
            elif conf < 0.9:
                confidence_ranges["0.7-0.9"] += 1
            else:
                confidence_ranges["0.9-1.0"] += 1
        
        # å®Œæ•´æ€§è¯„åˆ†ï¼ˆæœ‰åˆ†ææ–‡æœ¬çš„æ¯”ä¾‹ï¼‰
        complete_reports = sum(
            1 for r in reports 
            if r.qwen_analysis and len(r.qwen_analysis) > 0
        )
        completeness = complete_reports / len(reports) if reports else 0.0
        
        return {
            "success": True,
            "data": {
                "period_days": days,
                "total_reports": len(reports),
                "data_coverage": {
                    "news_coverage": coverage["news"] / len(reports),
                    "whale_coverage": coverage["whale"] / len(reports),
                    "onchain_coverage": coverage["onchain"] / len(reports),
                },
                "confidence_distribution": confidence_ranges,
                "completeness_score": completeness
            }
        }
    
    except Exception as e:
        logger.error(f"è·å–æ•°æ®è´¨é‡ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
