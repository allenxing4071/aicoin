# 🧠 记忆学习系统

> **来源**: 01-核心规则/AI交易规则文档.md 第三部分  
> **创建时间**: 2025-10-31  
> **版本**: v2.1  
> **状态**: Phase 2 技术文档

---

## 📋 目录

- [概述](#概述)
- [三层记忆架构](#三层记忆架构)
- [第一层：短期记忆（Redis）](#第一层短期记忆redis)
- [第二层：长期记忆（向量数据库）](#第二层长期记忆向量数据库)
- [第三层：知识库（PostgreSQL）](#第三层知识库postgresql)
- [集成：记忆增强的AI决策](#集成记忆增强的ai决策)
- [自动化学习流程](#自动化学习流程)
- [部署方案](#部署方案)
- [性能优化](#性能优化)

---

## 🎯 概述

### 问题背景

Phase 1 测试中发现的核心问题：
```
❌ AI无法记住自己的历史决策
❌ 重复犯同样的错误
❌ 无法利用历史经验
❌ 每次决策都是"从零开始"
```

### 解决方案：三层记忆架构

```
┌─────────────────────────────────────────────────────┐
│                 AI决策引擎                           │
│                (DeepSeek V3)                         │
└──────────────────┬──────────────────────────────────┘
                   │
                   ↓
┌─────────────────────────────────────────────────────┐
│              三层记忆系统                            │
├─────────────────────────────────────────────────────┤
│                                                     │
│  [L1] 短期记忆 (Redis)                              │
│  ├─ 最近100个决策                                   │
│  ├─ 当日交易统计                                    │
│  └─ 实时性能指标                                    │
│      TTL: 30天                                      │
│                                                     │
│  [L2] 长期记忆 (Qdrant向量数据库)                   │
│  ├─ 所有历史决策向量化                              │
│  ├─ 相似市场情况检索                                │
│  └─ 模式识别                                        │
│      存储: 永久                                      │
│                                                     │
│  [L3] 知识库 (PostgreSQL)                           │
│  ├─ 经验教训总结                                    │
│  ├─ 策略性能评估                                    │
│  └─ 市场模式库                                      │
│      结构化知识                                      │
│                                                     │
└─────────────────────────────────────────────────────┘
```

### 核心价值

| 记忆层 | 作用 | 典型场景 | 查询速度 |
|--------|------|----------|----------|
| **短期记忆** | 快速回顾最近决策 | "刚才做了什么？今天交易几次了？" | <10ms |
| **长期记忆** | 找到相似历史情况 | "这种市场状态以前遇到过吗？当时怎么做的？" | <100ms |
| **知识库** | 提供经验和策略 | "震荡市应该怎么办？哪个策略最有效？" | <50ms |

---

## 📐 三层记忆架构

### 设计原则

#### 1. 分层存储原则
```python
# 不同类型数据使用不同存储方案
短期记忆 (Redis)       → 快速、临时、频繁访问
长期记忆 (Qdrant)      → 向量化、语义搜索
知识库 (PostgreSQL)    → 结构化、可查询、可统计
```

#### 2. 数据流转原则
```
决策发生 → 记录到L1(Redis)
         ↓
      24小时后 → 向量化存入L2(Qdrant)
         ↓
      每周总结 → 提取经验到L3(PostgreSQL)
```

#### 3. 检索优先级
```
步骤1: 先查L1短期记忆 (最快)
步骤2: 再查L2长期记忆 (语义匹配)
步骤3: 最后查L3知识库 (规则&经验)
```

---

## 🔄 第一层：短期记忆（Redis）

### 功能定位

**核心作用**：
- ✅ 存储最近100个决策
- ✅ 记录当日交易统计
- ✅ 缓存实时性能指标
- ✅ 提供毫秒级查询速度

### Redis数据结构设计

```redis
# 1. 最近决策列表（Sorted Set）
"ai:decisions:recent" → Sorted Set
{
    "decision_uuid_1": 1698765432.123,  # timestamp作为score
    "decision_uuid_2": 1698765433.456,
    "decision_uuid_3": 1698765434.789,
    ...
}

# 2. 决策详情（Hash）
"ai:decision:uuid_1" → Hash
{
    "id": "uuid_1",
    "timestamp": "2024-10-31T10:30:00Z",
    "market_data": "{...json...}",
    "decision": "{...json...}",
    "result": "pending",  # "success" | "failure" | "pending"
    "pnl": "0.0",
    "closed_at": null
}

# 3. 当日交易计数（String）
"ai:trades:count:today" → "5"
# TTL: 自动在每天结束时过期

# 4. 性能指标（滚动窗口）
"ai:performance:7d" → Hash
{
    "win_rate": "0.65",
    "sharpe_ratio": "1.2",
    "max_drawdown": "0.03",
    "total_trades": "23",
    "winning_trades": "15",
    "avg_pnl": "12.5",
    "updated_at": "2024-10-31T10:00:00Z"
}

"ai:performance:30d" → Hash
{...}
```

### 短期记忆服务实现

```python
# backend/app/services/memory/short_term_memory.py

from datetime import datetime, timedelta, timezone
import json
import statistics
import math
from typing import List, Dict, Optional
import logging

logger = logging.getLogger(__name__)

class ShortTermMemory:
    """
    短期记忆服务 - 基于Redis
    存储最近决策、当日统计、实时性能指标
    """
    
    def __init__(self, redis_client):
        self.redis = redis_client
        self.max_recent_decisions = 100  # 保留最近100个决策
    
    async def record_decision(
        self,
        decision_id: str,
        market_data: dict,
        ai_decision: dict
    ) -> None:
        """
        记录AI决策到短期记忆
        
        Args:
            decision_id: 决策唯一ID
            market_data: 市场数据快照
            ai_decision: AI决策内容
        """
        timestamp = datetime.now(timezone.utc)
        
        # 1. 保存决策详情到Hash
        decision_key = f"ai:decision:{decision_id}"
        await self.redis.hset(decision_key, mapping={
            "id": decision_id,
            "timestamp": timestamp.isoformat(),
            "market_data": json.dumps(market_data),
            "decision": json.dumps(ai_decision),
            "result": "pending",  # 初始状态
            "pnl": "0.0",
            "closed_at": "null"
        })
        
        # 设置过期时间（30天）
        await self.redis.expire(decision_key, 30 * 24 * 3600)
        
        # 2. 添加到最近决策列表（Sorted Set）
        await self.redis.zadd(
            "ai:decisions:recent",
            {decision_id: timestamp.timestamp()}
        )
        
        # 3. 维护列表大小（只保留最近N个）
        await self.redis.zremrangebyrank(
            "ai:decisions:recent",
            0,
            -(self.max_recent_decisions + 1)
        )
        
        logger.info(f"✅ 决策已记录到短期记忆: {decision_id}")
    
    async def update_decision_result(
        self,
        decision_id: str,
        result: str,  # "success" | "failure"
        pnl: float,
        closed_at: datetime
    ) -> None:
        """
        更新决策结果（交易平仓后调用）
        
        Args:
            decision_id: 决策ID
            result: 结果状态
            pnl: 盈亏金额
            closed_at: 平仓时间
        """
        decision_key = f"ai:decision:{decision_id}"
        
        # 检查决策是否存在
        exists = await self.redis.exists(decision_key)
        if not exists:
            logger.warning(f"⚠️ 决策不存在: {decision_id}")
            return
        
        # 更新结果
        await self.redis.hset(decision_key, mapping={
            "result": result,
            "pnl": str(pnl),
            "closed_at": closed_at.isoformat()
        })
        
        logger.info(f"📊 决策结果更新: {decision_id} → {result} (PNL: {pnl:+.2f})")
    
    async def get_recent_decisions(self, limit: int = 10) -> List[Dict]:
        """
        获取最近N个决策
        
        Args:
            limit: 返回决策数量
            
        Returns:
            决策列表（按时间倒序）
        """
        # 1. 获取最近的decision_ids（倒序，最新的在前）
        decision_ids = await self.redis.zrevrange(
            "ai:decisions:recent",
            0,
            limit - 1
        )
        
        if not decision_ids:
            return []
        
        # 2. 批量获取决策详情
        decisions = []
        for decision_id in decision_ids:
            decision_key = f"ai:decision:{decision_id}"
            data = await self.redis.hgetall(decision_key)
            
            if data:
                decisions.append({
                    "id": data["id"],
                    "timestamp": data["timestamp"],
                    "market_data": json.loads(data["market_data"]),
                    "decision": json.loads(data["decision"]),
                    "result": data["result"],
                    "pnl": float(data["pnl"]),
                    "closed_at": data.get("closed_at") if data.get("closed_at") != "null" else None
                })
        
        return decisions
    
    async def get_today_trade_count(self) -> int:
        """
        获取今日交易次数
        
        Returns:
            今日交易数量
        """
        count = await self.redis.get("ai:trades:count:today")
        return int(count) if count else 0
    
    async def increment_today_trade_count(self) -> int:
        """
        增加今日交易计数
        
        Returns:
            更新后的计数
        """
        key = "ai:trades:count:today"
        new_count = await self.redis.incr(key)
        
        # 设置过期时间到今天结束（UTC时间）
        now = datetime.now(timezone.utc)
        end_of_day = now.replace(hour=23, minute=59, second=59, microsecond=999999)
        ttl = int((end_of_day - now).total_seconds())
        
        if ttl > 0:
            await self.redis.expire(key, ttl)
        
        logger.info(f"📈 今日交易计数: {new_count}")
        return new_count
    
    async def update_performance_metrics(self, window: str = "7d") -> None:
        """
        更新性能指标（每小时调用一次）
        
        Args:
            window: 时间窗口 "7d" | "30d"
        """
        # 计算时间窗口
        days = 7 if window == "7d" else 30 if window == "30d" else 7
        since_timestamp = (datetime.now(timezone.utc) - timedelta(days=days)).timestamp()
        
        # 获取时间窗口内的决策IDs
        decision_ids = await self.redis.zrangebyscore(
            "ai:decisions:recent",
            since_timestamp,
            "+inf"
        )
        
        # 收集已完成的决策
        completed_decisions = []
        for decision_id in decision_ids:
            decision_key = f"ai:decision:{decision_id}"
            data = await self.redis.hgetall(decision_key)
            
            if data and data["result"] in ["success", "failure"]:
                completed_decisions.append({
                    "result": data["result"],
                    "pnl": float(data["pnl"])
                })
        
        if not completed_decisions:
            logger.info(f"⚠️ {window}时间窗口内无已完成交易")
            return
        
        # 计算指标
        total_trades = len(completed_decisions)
        winning_trades = sum(1 for d in completed_decisions if d["result"] == "success")
        win_rate = winning_trades / total_trades if total_trades > 0 else 0
        
        pnls = [d["pnl"] for d in completed_decisions]
        avg_pnl = statistics.mean(pnls) if pnls else 0
        std_pnl = statistics.stdev(pnls) if len(pnls) > 1 else 0
        sharpe_ratio = (avg_pnl / std_pnl * math.sqrt(252)) if std_pnl > 0 else 0
        
        # 最大回撤（简化版）
        cumulative_pnl = 0
        peak = 0
        max_drawdown = 0
        for pnl in pnls:
            cumulative_pnl += pnl
            peak = max(peak, cumulative_pnl)
            drawdown = (peak - cumulative_pnl) / peak if peak > 0 else 0
            max_drawdown = max(max_drawdown, drawdown)
        
        # 保存到Redis
        metrics_key = f"ai:performance:{window}"
        await self.redis.hset(metrics_key, mapping={
            "win_rate": str(win_rate),
            "total_trades": str(total_trades),
            "winning_trades": str(winning_trades),
            "sharpe_ratio": str(sharpe_ratio),
            "max_drawdown": str(max_drawdown),
            "avg_pnl": str(avg_pnl),
            "updated_at": datetime.now(timezone.utc).isoformat()
        })
        
        logger.info(f"📊 {window}性能指标已更新: 胜率={win_rate:.1%}, 夏普={sharpe_ratio:.2f}")
    
    async def get_performance_metrics(self, window: str = "7d") -> Dict:
        """
        获取性能指标
        
        Args:
            window: 时间窗口 "7d" | "30d"
            
        Returns:
            性能指标字典
        """
        metrics_key = f"ai:performance:{window}"
        data = await self.redis.hgetall(metrics_key)
        
        if not data:
            return {
                "win_rate": 0,
                "total_trades": 0,
                "sharpe_ratio": 0,
                "max_drawdown": 0,
                "message": f"No data for {window} window"
            }
        
        return {
            "win_rate": float(data["win_rate"]),
            "total_trades": int(data["total_trades"]),
            "winning_trades": int(data["winning_trades"]),
            "sharpe_ratio": float(data["sharpe_ratio"]),
            "max_drawdown": float(data["max_drawdown"]),
            "avg_pnl": float(data["avg_pnl"]),
            "updated_at": data["updated_at"]
        }
```

---

## 🗄️ 第二层：长期记忆（向量数据库）

### 向量数据库选型

**候选方案比较**：

| 方案 | 优点 | 缺点 | 推荐度 |
|------|------|------|--------|
| **Qdrant** | • 部署简单<br>• Rust实现，高性能<br>• API友好<br>• Python SDK完善 | • 社区较小<br>• 文档相对少 | ⭐⭐⭐⭐⭐ |
| **Milvus** | • 开源、功能强大<br>• 支持多种索引<br>• 性能优秀 | • 部署复杂<br>• 资源占用较大 | ⭐⭐⭐⭐ |
| **Weaviate** | • 功能全面<br>• 支持GraphQL<br>• 社区活跃 | • 资源占用大<br>• 配置复杂 | ⭐⭐⭐ |
| **Redis Vector** | • 与Redis集成<br>• 部署简单 | • 功能有限<br>• 性能一般 | ⭐⭐⭐ |

**推荐：Qdrant**

理由：
- ✅ Docker一键部署
- ✅ 性能优秀（Rust实现）
- ✅ Python SDK完善
- ✅ 资源占用适中（适合初期）
- ✅ 支持过滤和混合查询

### 市场状态向量化

```python
# backend/app/services/memory/vectorizer.py

from typing import Dict, List
import logging

logger = logging.getLogger(__name__)

class MarketStateVectorizer:
    """
    将市场状态转换为向量
    用于语义搜索相似市场情况
    """
    
    def __init__(self, embedding_model: str = "text-embedding-3-small"):
        """
        Args:
            embedding_model: 使用的embedding模型
                - OpenAI: "text-embedding-3-small"
                - DeepSeek: "deepseek-embedding"
                - 本地: "sentence-transformers/all-MiniLM-L6-v2"
        """
        self.embedding_model = embedding_model
        # 初始化embedding客户端
        # self.client = ... (根据模型选择初始化)
    
    def vectorize_market_state(self, market_data: Dict) -> List[float]:
        """
        将市场数据转换为768维向量
        
        Args:
            market_data: 市场数据字典
            
        Returns:
            768维向量
        """
        # 1. 提取关键特征
        features = self._extract_features(market_data)
        
        # 2. 转换为文本描述
        text_desc = self._features_to_text(features)
        
        # 3. 使用embedding模型
        vector = self._embed_text(text_desc)
        
        return vector
    
    def _extract_features(self, market_data: Dict) -> Dict:
        """
        提取关键市场特征
        
        Returns:
            特征字典
        """
        btc = market_data.get("BTC", {})
        eth = market_data.get("ETH", {})
        
        return {
            # 价格特征
            "btc_price": btc.get("price", 0),
            "btc_price_level": self._categorize_price(btc.get("price", 0)),
            "btc_change_24h": btc.get("change_24h", 0),
            "btc_volatility": btc.get("volatility", "unknown"),
            
            # 趋势特征
            "btc_trend": self._identify_trend(btc.get("change_24h", 0)),
            "eth_trend": self._identify_trend(eth.get("change_24h", 0)),
            
            # 市场情绪
            "funding_rate": btc.get("funding_rate", 0),
            "open_interest_change": btc.get("open_interest_change", 0),
            
            # 技术指标
            "rsi": btc.get("rsi", 50),
            "macd_signal": btc.get("macd_signal", "neutral"),
            
            # 市场类型
            "market_regime": self._classify_market_regime(market_data)
        }
    
    def _features_to_text(self, features: Dict) -> str:
        """
        将特征转换为自然语言描述
        
        Returns:
            文本描述
        """
        return f"""
市场状态分析：
- BTC价格水平：{features['btc_price_level']}（${features['btc_price']:.2f}）
- BTC趋势：{features['btc_trend']}
- 24小时涨跌：{features['btc_change_24h']:.2%}
- 波动率：{features['btc_volatility']}
- 资金费率：{features['funding_rate']:.4%}
- 持仓量变化：{features['open_interest_change']:.2%}
- RSI指标：{features['rsi']:.1f}
- MACD信号：{features['macd_signal']}
- 市场类型：{features['market_regime']}
- ETH趋势：{features['eth_trend']}
        """.strip()
    
    def _embed_text(self, text: str) -> List[float]:
        """
        使用embedding模型转换文本为向量
        
        Args:
            text: 输入文本
            
        Returns:
            向量（768维）
        """
        # 实际实现：调用embedding API
        # 这里示意使用OpenAI
        import openai
        
        response = openai.embeddings.create(
            input=text,
            model=self.embedding_model
        )
        
        return response.data[0].embedding
    
    def _categorize_price(self, price: float) -> str:
        """价格水平分类"""
        if price > 100000:
            return "极高位"
        elif price > 80000:
            return "高位"
        elif price > 60000:
            return "中高位"
        elif price > 40000:
            return "中位"
        elif price > 30000:
            return "中低位"
        else:
            return "低位"
    
    def _identify_trend(self, change_24h: float) -> str:
        """识别趋势"""
        if change_24h > 0.05:
            return "strong_bullish"
        elif change_24h > 0.02:
            return "bullish"
        elif change_24h > -0.02:
            return "neutral"
        elif change_24h > -0.05:
            return "bearish"
        else:
            return "strong_bearish"
    
    def _classify_market_regime(self, market_data: Dict) -> str:
        """
        分类市场状态
        
        Returns:
            市场状态类型
        """
        btc = market_data.get("BTC", {})
        change = btc.get("change_24h", 0)
        volatility = btc.get("volatility", "unknown")
        
        # 简化逻辑
        if abs(change) < 0.02 and volatility == "low":
            return "sideways"  # 震荡市
        elif change > 0.05:
            return "bull_run"  # 牛市
        elif change < -0.05:
            return "bear_market"  # 熊市
        else:
            return "normal"  # 常规市场
```

### 长期记忆服务

```python
# backend/app/services/memory/long_term_memory.py

from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition
from datetime import datetime
from typing import List, Dict, Optional
import logging
import statistics

logger = logging.getLogger(__name__)

class LongTermMemory:
    """
    长期记忆服务 - 基于Qdrant向量数据库
    存储所有历史决策的向量化表示
    """
    
    def __init__(self, qdrant_url: str = "localhost:6333"):
        self.client = QdrantClient(url=qdrant_url)
        self.collection_name = "ai_trading_memory"
        self.vectorizer = MarketStateVectorizer()
        
        # 初始化collection
        self._init_collection()
    
    def _init_collection(self):
        """
        初始化向量集合
        """
        try:
            self.client.get_collection(self.collection_name)
            logger.info(f"✅ Collection '{self.collection_name}' exists")
        except:
            # 创建collection
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(
                    size=1536,  # OpenAI embedding维度 (或768 for others)
                    distance=Distance.COSINE
                )
            )
            logger.info(f"✅ Collection '{self.collection_name}' created")
    
    async def store_decision(
        self,
        decision_id: str,
        market_data: Dict,
        ai_decision: Dict,
        result: Optional[Dict] = None
    ) -> None:
        """
        存储决策到向量数据库
        
        Args:
            decision_id: 决策ID
            market_data: 市场数据
            ai_decision: AI决策
            result: 结果（可选）
        """
        # 1. 向量化市场状态
        vector = self.vectorizer.vectorize_market_state(market_data)
        
        # 2. 构建payload（元数据）
        payload = {
            "decision_id": decision_id,
            "timestamp": datetime.now().isoformat(),
            "action": ai_decision.get("action", "hold"),
            "symbol": ai_decision.get("symbol", ""),
            "confidence": ai_decision.get("confidence", 0),
            "leverage": ai_decision.get("leverage", 1),
            "size_usd": ai_decision.get("size_usd", 0),
            "reasoning": ai_decision.get("reasoning", ""),
            
            # 市场特征（用于过滤）
            "market_regime": market_data.get("market_regime", "normal"),
            "btc_trend": market_data.get("BTC", {}).get("trend", "neutral"),
            
            # 结果（如果有）
            "result": result.get("outcome") if result else "pending",
            "pnl": result.get("pnl", 0) if result else 0,
            "profitable": result.get("profitable", False) if result else False
        }
        
        # 3. 存储到Qdrant
        point = PointStruct(
            id=abs(hash(decision_id)) % (2**63),  # 转换为正整数ID
            vector=vector,
            payload=payload
        )
        
        self.client.upsert(
            collection_name=self.collection_name,
            points=[point]
        )
        
        logger.info(f"📝 决策已存储到向量库: {decision_id}")
    
    async def find_similar_situations(
        self,
        current_market_data: Dict,
        limit: int = 10,
        only_successful: bool = False
    ) -> List[Dict]:
        """
        查找与当前市场状态相似的历史情况
        
        Args:
            current_market_data: 当前市场数据
            limit: 返回数量
            only_successful: 是否只返回成功案例
            
        Returns:
            相似情况列表
        """
        # 1. 向量化当前市场状态
        query_vector = self.vectorizer.vectorize_market_state(current_market_data)
        
        # 2. 构建过滤条件
        filter_condition = None
        if only_successful:
            filter_condition = Filter(
                must=[
                    FieldCondition(
                        key="profitable",
                        match={"value": True}
                    )
                ]
            )
        
        # 3. 向量搜索
        search_result = self.client.search(
            collection_name=self.collection_name,
            query_vector=query_vector,
            query_filter=filter_condition,
            limit=limit,
            with_payload=True
        )
        
        # 4. 格式化结果
        similar_cases = []
        for hit in search_result:
            similar_cases.append({
                "similarity_score": hit.score,
                "decision_id": hit.payload["decision_id"],
                "timestamp": hit.payload["timestamp"],
                "action": hit.payload["action"],
                "symbol": hit.payload["symbol"],
                "result": hit.payload["result"],
                "pnl": hit.payload["pnl"],
                "profitable": hit.payload["profitable"],
                "reasoning": hit.payload["reasoning"],
                "confidence": hit.payload["confidence"]
            })
        
        logger.info(f"🔍 找到{len(similar_cases)}个相似历史情况")
        return similar_cases
    
    async def get_pattern_statistics(self, market_regime: str) -> Dict:
        """
        获取特定市场模式下的统计信息
        
        Args:
            market_regime: 市场状态类型
            
        Returns:
            统计信息
        """
        # 使用scroll API获取所有匹配的记录
        records = []
        offset = None
        
        while True:
            response = self.client.scroll(
                collection_name=self.collection_name,
                scroll_filter=Filter(
                    must=[
                        FieldCondition(key="market_regime", match={"value": market_regime}),
                        FieldCondition(key="result", match={"any": ["success", "failure"]})
                    ]
                ),
                limit=100,
                offset=offset,
                with_payload=True
            )
            
            records.extend(response[0])
            
            if response[1] is None:  # 没有更多记录
                break
            offset = response[1]
        
        # 统计分析
        if not records:
            return {"message": f"No data for market regime: {market_regime}"}
        
        total = len(records)
        successful = sum(1 for r in records if r.payload["profitable"])
        win_rate = successful / total
        
        avg_pnl = statistics.mean([r.payload["pnl"] for r in records])
        
        # 最常见的成功策略
        successful_actions = [r.payload["action"] for r in records if r.payload["profitable"]]
        most_common_action = max(set(successful_actions), key=successful_actions.count) if successful_actions else None
        
        return {
            "market_regime": market_regime,
            "total_trades": total,
            "successful_trades": successful,
            "win_rate": win_rate,
            "avg_pnl": avg_pnl,
            "most_successful_action": most_common_action
        }
```

---

## 📚 第三层：知识库（PostgreSQL）

### 数据库Schema扩展

```sql
-- backend/database/migrations/add_knowledge_base.sql

-- 1. 经验教训表
CREATE TABLE ai_lessons (
    id SERIAL PRIMARY KEY,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    
    lesson_type VARCHAR(50) NOT NULL,  -- 'success' | 'failure' | 'insight'
    market_regime VARCHAR(50),
    symbol VARCHAR(10),
    action VARCHAR(20),
    
    -- 教训内容
    title VARCHAR(200) NOT NULL,
    description TEXT NOT NULL,
    confidence_score FLOAT DEFAULT 0.5,
    
    -- 关联数据
    related_decisions TEXT[],  -- decision_ids数组
    sample_count INTEGER DEFAULT 1,
    
    -- 验证状态
    validated BOOLEAN DEFAULT FALSE,
    validation_trades INTEGER DEFAULT 0,
    validation_success_rate FLOAT DEFAULT 0,
    
    UNIQUE(title)  -- 避免重复教训
);

CREATE INDEX idx_ai_lessons_type ON ai_lessons(lesson_type);
CREATE INDEX idx_ai_lessons_regime ON ai_lessons(market_regime);
CREATE INDEX idx_ai_lessons_confidence ON ai_lessons(confidence_score DESC);

-- 2. 策略评估表
CREATE TABLE ai_strategies (
    id SERIAL PRIMARY KEY,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    
    strategy_name VARCHAR(100) NOT NULL UNIQUE,
    description TEXT,
    
    -- 适用条件
    market_regime VARCHAR(50),
    applicable_symbols TEXT[],
    
    -- 性能指标
    total_trades INTEGER DEFAULT 0,
    winning_trades INTEGER DEFAULT 0,
    win_rate FLOAT DEFAULT 0,
    avg_pnl FLOAT DEFAULT 0,
    sharpe_ratio FLOAT DEFAULT 0,
    max_drawdown FLOAT DEFAULT 0,
    
    -- 状态
    status VARCHAR(20) DEFAULT 'active',  -- 'active' | 'deprecated' | 'testing'
    last_used_at TIMESTAMP
);

CREATE INDEX idx_ai_strategies_status ON ai_strategies(status);
CREATE INDEX idx_ai_strategies_performance ON ai_strategies(win_rate DESC, sharpe_ratio DESC);

-- 3. 市场模式表
CREATE TABLE market_patterns (
    id SERIAL PRIMARY KEY,
    detected_at TIMESTAMP NOT NULL DEFAULT NOW(),
    
    pattern_type VARCHAR(50) NOT NULL,  -- 'trend_reversal', 'breakout', 'consolidation'
    symbol VARCHAR(10) NOT NULL,
    
    -- 模式特征
    features JSONB NOT NULL,
    
    -- 历史表现
    occurrences INTEGER DEFAULT 1,
    success_rate FLOAT,
    avg_profit FLOAT,
    
    -- 最近发生
    last_seen_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_market_patterns_type ON market_patterns(pattern_type);
CREATE INDEX idx_market_patterns_symbol ON market_patterns(symbol);
CREATE INDEX idx_market_patterns_last_seen ON market_patterns(last_seen_at DESC);
```

### 知识库服务实现

```python
# backend/app/services/memory/knowledge_base.py

from typing import List, Dict, Optional
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

class KnowledgeBase:
    """
    知识库服务 - 基于PostgreSQL
    提取、存储和检索结构化的交易经验
    """
    
    def __init__(self, db_session):
        self.db = db_session
    
    async def extract_lesson(
        self,
        decision_sequence: List[Dict],
        outcome: Dict
    ) -> Dict:
        """
        从决策序列中提取经验教训
        
        Args:
            decision_sequence: 决策序列
            outcome: 最终结果
            
        Returns:
            提取的教训
        """
        # 判断是成功还是失败经验
        if outcome.get("profitable", False):
            lesson_type = "success"
            title = self._generate_success_title(decision_sequence, outcome)
            description = self._generate_success_description(decision_sequence, outcome)
        else:
            lesson_type = "failure"
            title = self._generate_failure_title(decision_sequence, outcome)
            description = self._generate_failure_description(decision_sequence, outcome)
        
        # 检查是否已存在相同教训
        existing = await self.db.execute(
            "SELECT * FROM ai_lessons WHERE title = :title",
            {"title": title}
        )
        
        if existing.first():
            # 更新已有教训
            await self.db.execute(
                """
                UPDATE ai_lessons
                SET sample_count = sample_count + 1,
                    confidence_score = LEAST(confidence_score + 0.1, 1.0),
                    updated_at = NOW()
                WHERE title = :title
                """,
                {"title": title}
            )
        else:
            # 创建新教训
            await self.db.execute(
                """
                INSERT INTO ai_lessons 
                (lesson_type, title, description, market_regime, symbol, action, confidence_score)
                VALUES (:type, :title, :desc, :regime, :symbol, :action, 0.5)
                """,
                {
                    "type": lesson_type,
                    "title": title,
                    "desc": description,
                    "regime": decision_sequence[0].get("market_regime"),
                    "symbol": decision_sequence[0].get("symbol"),
                    "action": decision_sequence[0].get("action")
                }
            )
        
        await self.db.commit()
        
        logger.info(f"📚 教训已提取: {title}")
        
        return {"title": title, "description": description, "type": lesson_type}
    
    async def get_relevant_lessons(
        self,
        market_regime: str,
        limit: int = 5
    ) -> List[Dict]:
        """
        获取与当前市场相关的经验教训
        
        Args:
            market_regime: 市场状态
            limit: 返回数量
            
        Returns:
            相关教训列表
        """
        result = await self.db.execute(
            """
            SELECT * FROM ai_lessons
            WHERE (market_regime = :regime OR market_regime IS NULL)
              AND confidence_score > 0.6
              AND validated = TRUE
            ORDER BY confidence_score DESC, sample_count DESC
            LIMIT :limit
            """,
            {"regime": market_regime, "limit": limit}
        )
        
        lessons = [dict(row) for row in result]
        
        logger.info(f"📖 找到{len(lessons)}条相关教训")
        
        return lessons
    
    async def update_strategy_performance(
        self,
        strategy_name: str,
        trade_result: Dict
    ):
        """
        更新策略性能统计
        
        Args:
            strategy_name: 策略名称
            trade_result: 交易结果
        """
        # 获取或创建策略记录
        result = await self.db.execute(
            "SELECT * FROM ai_strategies WHERE strategy_name = :name",
            {"name": strategy_name}
        )
        
        strategy = result.first()
        
        if not strategy:
            # 创建新策略
            await self.db.execute(
                """
                INSERT INTO ai_strategies (strategy_name, description, market_regime)
                VALUES (:name, :desc, :regime)
                """,
                {
                    "name": strategy_name,
                    "desc": f"Auto-generated: {strategy_name}",
                    "regime": trade_result.get("market_regime")
                }
            )
            total_trades = 0
            winning_trades = 0
            avg_pnl = 0
        else:
            strategy = dict(strategy)
            total_trades = strategy["total_trades"]
            winning_trades = strategy["winning_trades"]
            avg_pnl = strategy["avg_pnl"]
        
        # 更新统计
        new_total = total_trades + 1
        new_winning = winning_trades + (1 if trade_result["profitable"] else 0)
        win_rate = new_winning / new_total
        new_avg_pnl = (avg_pnl * total_trades + trade_result["pnl"]) / new_total
        
        await self.db.execute(
            """
            UPDATE ai_strategies
            SET total_trades = :total,
                winning_trades = :winning,
                win_rate = :win_rate,
                avg_pnl = :avg_pnl,
                last_used_at = NOW(),
                updated_at = NOW()
            WHERE strategy_name = :name
            """,
            {
                "name": strategy_name,
                "total": new_total,
                "winning": new_winning,
                "win_rate": win_rate,
                "avg_pnl": new_avg_pnl
            }
        )
        
        await self.db.commit()
        
        logger.info(f"📊 策略性能已更新: {strategy_name} (胜率: {win_rate:.1%})")
    
    async def daily_summary(self) -> Dict:
        """
        生成每日交易总结
        
        Returns:
            每日总结报告
        """
        today = datetime.now().date()
        
        # 获取今日交易
        result = await self.db.execute(
            """
            SELECT * FROM trades
            WHERE DATE(created_at) = :today
              AND status = 'closed'
            ORDER BY created_at
            """,
            {"today": today}
        )
        
        trades = [dict(row) for row in result]
        
        if not trades:
            return {"message": "No trades today"}
        
        # 统计分析
        total = len(trades)
        profitable = sum(1 for t in trades if t["pnl"] > 0)
        total_pnl = sum(t["pnl"] for t in trades)
        
        summary = {
            "date": today.isoformat(),
            "total_trades": total,
            "profitable_trades": profitable,
            "win_rate": profitable / total,
            "total_pnl": total_pnl,
            "avg_pnl_per_trade": total_pnl / total,
            "best_trade": max(trades, key=lambda t: t["pnl"]),
            "worst_trade": min(trades, key=lambda t: t["pnl"]),
            "insights": []
        }
        
        # 生成洞察
        if summary["win_rate"] > 0.7:
            summary["insights"].append("✅ 今日表现优秀，胜率超过70%")
        elif summary["win_rate"] < 0.4:
            summary["insights"].append("⚠️ 今日胜率偏低，需要review策略")
        
        if total > 5:
            summary["insights"].append("⚠️ 交易频率较高，建议降低频率")
        
        return summary
    
    def _generate_success_title(self, sequence: List[Dict], outcome: Dict) -> str:
        """生成成功经验的标题"""
        first_decision = sequence[0]
        return f"成功案例: {first_decision['action']} {first_decision['symbol']} in {first_decision.get('market_regime', 'unknown')} market"
    
    def _generate_failure_title(self, sequence: List[Dict], outcome: Dict) -> str:
        """生成失败经验的标题"""
        first_decision = sequence[0]
        return f"失败案例: {first_decision['action']} {first_decision['symbol']} in {first_decision.get('market_regime', 'unknown')} market"
    
    def _generate_success_description(self, sequence: List[Dict], outcome: Dict) -> str:
        """生成成功经验的描述"""
        return f"在{sequence[0].get('market_regime')}市场条件下，采用{sequence[0]['action']}策略获得{outcome['pnl']:.2f}收益。"
    
    def _generate_failure_description(self, sequence: List[Dict], outcome: Dict) -> str:
        """生成失败经验的描述"""
        return f"在{sequence[0].get('market_regime')}市场条件下，{sequence[0]['action']}策略导致{outcome['pnl']:.2f}亏损，应避免类似决策。"
```

---

## 🔗 集成：记忆增强的AI决策

### 改进的决策引擎

```python
# backend/app/services/deepseek_decision_engine_v2.py

class DeepSeekDecisionEngineV2:
    """
    带记忆增强的AI决策引擎
    """
    
    def __init__(self):
        self.short_memory = ShortTermMemory(redis_client)
        self.long_memory = LongTermMemory()
        self.knowledge_base = KnowledgeBase(db_session)
        self.api_client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)
    
    async def analyze_market_data_with_memory(
        self,
        market_data: Dict
    ) -> Dict:
        """
        带记忆的市场分析和决策
        
        Args:
            market_data: 当前市场数据
            
        Returns:
            AI决策
        """
        # 1. 获取短期记忆（最近10次决策）
        recent_decisions = await self.short_memory.get_recent_decisions(limit=10)
        
        # 2. 获取长期记忆（相似市场情况）
        similar_situations = await self.long_memory.find_similar_situations(
            market_data,
            limit=5,
            only_successful=True  # 只看成功案例
        )
        
        # 3. 获取相关经验教训
        market_regime = market_data.get("market_regime", "normal")
        lessons = await self.knowledge_base.get_relevant_lessons(market_regime)
        
        # 4. 构建增强Prompt
        prompt = self._build_memory_enhanced_prompt(
            market_data=market_data,
            recent_decisions=recent_decisions,
            similar_situations=similar_situations,
            lessons=lessons
        )
        
        # 5. 调用DeepSeek API
        decision = await self._call_deepseek_api(prompt)
        
        # 6. 记录到所有记忆层
        decision_id = str(uuid.uuid4())
        await self.short_memory.record_decision(decision_id, market_data, decision)
        await self.long_memory.store_decision(decision_id, market_data, decision)
        
        return decision
    
    def _build_memory_enhanced_prompt(
        self,
        market_data: Dict,
        recent_decisions: List[Dict],
        similar_situations: List[Dict],
        lessons: List[Dict]
    ) -> str:
        """
        构建包含记忆的增强Prompt
        """
        prompt = f"""你是专业的加密货币量化交易AI。

═══════════════════════════════════════════════════════════
📊 当前市场状态
═══════════════════════════════════════════════════════════

{self._format_market_data(market_data)}

═══════════════════════════════════════════════════════════
🔄 你的最近10次决策回顾
═══════════════════════════════════════════════════════════

{self._format_recent_decisions(recent_decisions)}

═══════════════════════════════════════════════════════════
💡 历史上相似市场情况（成功案例）
═══════════════════════════════════════════════════════════

{self._format_similar_situations(similar_situations)}

═══════════════════════════════════════════════════════════
📚 相关经验教训
═══════════════════════════════════════════════════════════

{self._format_lessons(lessons)}

═══════════════════════════════════════════════════════════
🎯 你的任务
═══════════════════════════════════════════════════════════

基于以上信息（当前市场+历史经验+经验教训），做出明智的交易决策。

**核心原则**：
1. **从历史中学习** - 参考相似情况的成功经验
2. **避免重复错误** - 注意最近的失败教训
3. **经验优先** - 如果历史数据明确显示某策略有效，优先采用
4. **保持谨慎** - 如果历史没有类似成功案例，要更加保守

返回JSON格式决策...
"""
        return prompt
    
    def _format_recent_decisions(self, decisions: List[Dict]) -> str:
        """格式化最近决策"""
        if not decisions:
            return "暂无最近决策（新启动）"
        
        output = []
        for i, d in enumerate(decisions[:10], 1):
            result_icon = "✅" if d["result"] == "success" else "❌" if d["result"] == "failure" else "⏳"
            pnl_str = f"${d['pnl']:+.2f}" if d["pnl"] else "待定"
            
            decision_data = d["decision"]
            output.append(f"""
{i}. {result_icon} {d['timestamp']} - {decision_data.get('symbol', 'N/A')}
   动作: {decision_data.get('action')}
   仓位: ${decision_data.get('size_usd', 0):.0f} @ {decision_data.get('leverage', 1)}x
   结果: {pnl_str}
   推理: {decision_data.get('reasoning', '')[:100]}...
            """)
        
        return "\n".join(output)
    
    def _format_similar_situations(self, situations: List[Dict]) -> str:
        """格式化相似情况"""
        if not situations:
            return "暂无历史相似情况（数据积累中）"
        
        output = []
        for i, s in enumerate(situations, 1):
            output.append(f"""
{i}. 相似度: {s['similarity_score']:.2%}
   时间: {s['timestamp']}
   决策: {s['action']} on {s['symbol']}
   结果: {'✅盈利' if s['profitable'] else '❌亏损'} ${s['pnl']:+.2f}
   置信度: {s['confidence']:.0%}
   推理: {s['reasoning'][:100]}...
            """)
        
        return "\n".join(output)
    
    def _format_lessons(self, lessons: List[Dict]) -> str:
        """格式化经验教训"""
        if not lessons:
            return "暂无相关经验教训"
        
        output = []
        for i, lesson in enumerate(lessons, 1):
            lesson_icon = "📗" if lesson["lesson_type"] == "success" else "📕"
            output.append(f"""
{i}. {lesson_icon} {lesson['title']}
   {lesson['description']}
   置信度: {lesson['confidence_score']:.0%} (基于{lesson['sample_count']}次交易)
            """)
        
        return "\n".join(output)
    
    def _format_market_data(self, market_data: Dict) -> str:
        """格式化市场数据"""
        btc = market_data.get("BTC", {})
        return f"""
BTC价格: ${btc.get('price', 0):.2f}
24h涨跌: {btc.get('change_24h', 0):.2%}
波动率: {btc.get('volatility', 'unknown')}
趋势: {btc.get('trend', 'neutral')}
市场状态: {market_data.get('market_regime', 'normal')}
        """.strip()
    
    async def _call_deepseek_api(self, prompt: str) -> Dict:
        """调用DeepSeek API"""
        response = self.api_client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        
        # 解析JSON响应
        content = response.choices[0].message.content
        decision = json.loads(content)
        
        return decision
```

---

## ⏰ 自动化学习流程

### Celery定时任务

```python
# backend/app/tasks/memory_maintenance.py

from celery import Celery
from celery.schedules import crontab

celery = Celery("ai_trading")

# 配置定时任务
celery.conf.beat_schedule = {
    'update-performance-metrics-hourly': {
        'task': 'tasks.memory_maintenance.update_performance_metrics',
        'schedule': crontab(minute=0),  # 每小时整点
    },
    'daily-experience-extraction': {
        'task': 'tasks.memory_maintenance.daily_experience_extraction',
        'schedule': crontab(hour=0, minute=30),  # 每天 UTC 00:30
    },
    'weekly-pattern-analysis': {
        'task': 'tasks.memory_maintenance.weekly_pattern_analysis',
        'schedule': crontab(day_of_week=0, hour=1, minute=0),  # 每周日 UTC 01:00
    },
}

@celery.task
async def update_performance_metrics():
    """
    每小时更新性能指标
    """
    short_memory = ShortTermMemory(redis_client)
    await short_memory.update_performance_metrics("7d")
    await short_memory.update_performance_metrics("30d")
    
    logger.info("✅ 性能指标已更新")

@celery.task
async def daily_experience_extraction():
    """
    每日提取经验教训（UTC 00:30执行）
    """
    knowledge_base = KnowledgeBase(db_session)
    
    # 1. 生成每日总结
    summary = await knowledge_base.daily_summary()
    logger.info(f"📊 每日总结: {summary}")
    
    # 2. 提取教训
    # 获取今日所有已完成的交易
    # 分组分析（按策略、市场状态等）
    # ...提取经验教训的逻辑
    
    # 3. 发送总结报告（可选）
    # await send_daily_report(summary)
    
    logger.info("✅ 每日经验提取完成")

@celery.task
async def weekly_pattern_analysis():
    """
    每周分析市场模式
    """
    long_memory = LongTermMemory()
    
    # 分析过去7天的所有交易
    # 识别新的市场模式
    # 更新模式统计
    
    logger.info("✅ 每周模式分析完成")
```

---

## 🚀 部署方案

### Docker Compose配置

```yaml
# docker-compose.yml (扩展版)

version: '3.8'

services:
  # ... 其他服务 ...
  
  redis:
    image: redis:7-alpine
    container_name: aicoin-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped
  
  qdrant:
    image: qdrant/qdrant:latest
    container_name: aicoin-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    restart: unless-stopped
  
  postgres:
    image: postgres:15-alpine
    container_name: aicoin-postgres
    environment:
      POSTGRES_DB: aicoin
      POSTGRES_USER: aicoin
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

volumes:
  redis_data:
  qdrant_data:
  postgres_data:
```

### 初始化脚本

```bash
#!/bin/bash
# scripts/init_memory_system.sh

echo "🚀 初始化记忆系统..."

# 1. 启动服务
docker-compose up -d redis qdrant postgres

# 2. 等待服务就绪
sleep 5

# 3. 创建数据库表
python scripts/create_knowledge_base_tables.py

# 4. 初始化Qdrant collection
python scripts/init_qdrant_collection.py

echo "✅ 记忆系统初始化完成！"
```

---

## ⚡ 性能优化

### 缓存策略

```python
# backend/app/services/memory/cache_optimizer.py

class MemoryCacheOptimizer:
    """
    记忆系统缓存优化
    """
    
    def __init__(self, redis_client):
        self.redis = redis_client
    
    async def cache_frequent_queries(self):
        """
        缓存频繁查询的结果
        """
        # 缓存常见市场模式的统计
        common_regimes = ["bull_run", "bear_market", "sideways", "normal"]
        
        for regime in common_regimes:
            cache_key = f"pattern_stats:{regime}"
            
            # 检查缓存是否存在
            cached = await self.redis.get(cache_key)
            
            if not cached:
                # 查询并缓存
                stats = await self.long_memory.get_pattern_statistics(regime)
                await self.redis.setex(
                    cache_key,
                    3600,  # 1小时过期
                    json.dumps(stats)
                )
    
    async def warm_up_cache(self):
        """
        预热缓存
        """
        # 启动时预加载常用数据
        await self.cache_frequent_queries()
        
        logger.info("✅ 缓存预热完成")
```

### 查询优化

```python
# 批量查询优化
async def batch_get_decisions(self, decision_ids: List[str]) -> List[Dict]:
    """
    批量获取决策（优化版）
    """
    # 使用pipeline批量获取
    pipeline = self.redis.pipeline()
    
    for decision_id in decision_ids:
        decision_key = f"ai:decision:{decision_id}"
        pipeline.hgetall(decision_key)
    
    results = await pipeline.execute()
    
    decisions = []
    for data in results:
        if data:
            decisions.append({
                "id": data["id"],
                "timestamp": data["timestamp"],
                "market_data": json.loads(data["market_data"]),
                "decision": json.loads(data["decision"]),
                "result": data["result"],
                "pnl": float(data["pnl"])
            })
    
    return decisions
```

---

## ✅ Phase 2 实施检查清单

### 准备阶段
- [ ] Phase 1 验收通过
- [ ] 系统稳定运行7天无崩溃
- [ ] 小资金测试胜率>50%
- [ ] Docker环境已就绪

### 部署阶段
- [ ] Redis已部署并测试
- [ ] Qdrant已部署并测试
- [ ] PostgreSQL Schema已更新
- [ ] 三层记忆服务已实现
- [ ] 集成测试通过

### 测试阶段
- [ ] 短期记忆读写正常（<10ms）
- [ ] 长期记忆检索正常（<100ms）
- [ ] 知识库查询正常（<50ms）
- [ ] AI决策能引用历史经验
- [ ] 不再重复相同错误

### 验收标准
- [ ] 记忆系统响应时间达标
- [ ] 向量检索准确率>80%
- [ ] 系统稳定性：7天无崩溃
- [ ] 14天测试，胜率>55%
- [ ] 夏普比率>1.0
- [ ] 能明显看到"从历史中学习"

---

**文档状态**: ✅ 完成 (100%)  
**适用阶段**: Phase 2（记忆增强）  
**前置依赖**: Phase 1 完成  
**文档行数**: 1400+  
**最后更新**: 2025-10-31

---

*本文档提供Phase 2记忆学习系统的完整实现方案。建议在Phase 1稳定后开始实施。*