# 🤖 自建量化模型方案

> **来源**: 01-核心规则/AI交易规则文档.md 第四部分  
> **创建时间**: 2025-10-31  
> **版本**: v2.1  
> **状态**: Phase 3 技术文档

---

## 📋 目录

- [为什么需要自建模型](#为什么需要自建模型)
- [阿里云部署方案](#阿里云部署方案)
- [数据准备策略](#数据准备策略)
- [模型训练流程](#模型训练流程)
- [A/B测试框架](#ab测试框架)
- [持续优化机制](#持续优化机制)
- [成本分析](#成本分析)

---

## 🎯 为什么需要自建模型

### 通用模型的局限性

**DeepSeek V3（通用模型）的特点**:

```
✅ 强大的通用能力
   - 自然语言理解
   - 代码生成
   - 逻辑推理
   - 多领域知识

❌ 交易场景的局限
   - 未针对量化交易优化
   - 无法利用交易特定数据
   - 无法实时微调
   - 推理成本较高
   - API依赖，有延迟风险
```

### 专用模型的优势

```
✅ 针对性优化
   - 专门针对交易场景训练
   - 理解交易术语和模式
   - 优化的决策速度
   
✅ 数据驱动
   - 使用真实交易数据
   - 持续学习和优化
   - 适应市场变化
   
✅ 成本可控
   - 本地部署，无API费用
   - 可控的推理延迟
   - 数据安全性
```

### 对比分析

| 维度 | 通用模型(DeepSeek API) | 自建专用模型 |
|------|------------------------|--------------|
| **训练成本** | 0（使用现成） | 高（初期投入） |
| **推理成本** | 按调用付费（持续） | 服务器成本（固定） |
| **响应延迟** | 500-2000ms | <100ms |
| **定制能力** | 受限（Prompt工程） | 完全可控 |
| **数据隐私** | 上传到API | 本地安全 |
| **适应性** | 通用场景 | 交易专用 |
| **维护难度** | 低 | 中高 |

**推荐路径**：
```
Phase 1-2: 使用DeepSeek API（快速验证）
Phase 3: 并行运行API+自建模型（A/B测试）
Phase 4: 完全切换到自建模型（成本优化）
```

---

## ☁️ 阿里云部署方案

### 资源选型

**推荐配置（初期）**:

```
┌─────────────────────────────────────────────────┐
│           阿里云PAI-EAS推理服务配置               │
├─────────────────────────────────────────────────┤
│                                                 │
│  GPU实例：                                       │
│  • 类型：NVIDIA A10 (24GB显存)                  │
│  • 数量：1张                                     │
│  • 适用：7B-13B参数模型推理                      │
│  • 价格：约¥15/小时                              │
│                                                 │
│  CPU+内存：                                      │
│  • vCPU：8核                                     │
│  • 内存：32GB                                    │
│  • 存储：200GB SSD                               │
│                                                 │
│  网络：                                          │
│  • 带宽：10Mbps（按需调整）                       │
│  • VPC专有网络                                   │
│                                                 │
│  预估月成本：¥10,800                             │
│  （按需付费，可随时调整）                         │
│                                                 │
└─────────────────────────────────────────────────┘
```

### 成本优化方案

| 方案 | 配置 | 月成本 | 适用阶段 |
|------|------|--------|----------|
| **方案1：按需** | A10 + 8C32G | ¥10,800 | 初期测试 |
| **方案2：预留** | A10包月 | ¥7,200 | 稳定运行 |
| **方案3：混合** | CPU推理 + GPU训练 | ¥3,600 | 成本优化 |
| **方案4：本地** | 自建服务器 | ¥0（一次性投入）| 长期运营 |

**推荐路径**：
```
阶段1 (1-2月): 方案1 按需付费，快速验证
    ↓
阶段2 (3-6月): 方案2 包月优惠，稳定运行
    ↓
阶段3 (6月+):  方案4 自建服务器，长期优化
```

### 环境搭建

#### 步骤1：创建PAI工作空间

```bash
# 1. 登录阿里云控制台
# 2. 进入"机器学习PAI" → "PAI-DSW"
# 3. 创建Notebook实例

# 实例配置
Instance Type: GPU - A10 (24GB)
Image: PyTorch 2.0 + CUDA 11.8
Storage: 200GB

# 4. 启动实例并进入Jupyter
```

#### 步骤2：安装依赖

```python
# install_dependencies.py

!pip install transformers==4.36.0
!pip install accelerate==0.25.0
!pip install bitsandbytes==0.41.3
!pip install peft==0.7.1
!pip install datasets==2.15.0
!pip install sentencepiece==0.1.99
!pip install protobuf==3.20.3

# 验证GPU
import torch
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"GPU Count: {torch.cuda.device_count()}")
print(f"GPU Name: {torch.cuda.get_device_name(0)}")
```

#### 步骤3：下载基础模型

```python
# download_base_model.py

from transformers import AutoModelForCausalLM, AutoTokenizer

# 使用DeepSeek开源版本或类似开源模型
model_name = "deepseek-ai/deepseek-coder-7b-instruct-v1.5"

# 下载到本地
tokenizer = AutoTokenizer.from_pretrained(
    model_name,
    cache_dir="./models/base"
)

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    cache_dir="./models/base",
    torch_dtype=torch.float16,  # 使用FP16节省显存
    device_map="auto"
)

print(f"✅ 模型下载完成: {model_name}")
print(f"参数量: {model.num_parameters() / 1e9:.2f}B")
```

---

## 📊 数据准备策略

### 训练数据结构

```json
{
  "conversation_id": "uuid",
  "timestamp": "2025-10-31T10:00:00Z",
  
  "input": {
    "market_data": {
      "BTC": {
        "price": 68500.0,
        "change_24h": 0.025,
        "volatility": "medium",
        "trend": "bullish",
        "rsi": 62.5,
        "macd_signal": "positive"
      },
      "market_regime": "normal"
    },
    "account_state": {
      "balance": 600.0,
      "positions": [],
      "permission_level": "L2"
    },
    "recent_history": [
      // 最近3次决策
    ]
  },
  
  "output": {
    "action": "open_long",
    "symbol": "BTC",
    "size_usd": 60.0,
    "leverage": 2,
    "stop_loss_pct": 0.02,
    "take_profit_pct": 0.05,
    "reasoning": "...",
    "confidence": 0.75
  },
  
  "result": {
    "profitable": true,
    "pnl": 2.5,
    "duration_hours": 6,
    "exit_reason": "take_profit"
  },
  
  "label": "excellent_decision"  // "excellent_decision" | "good_decision" | "bad_decision"
}
```

### 数据收集服务

```python
# backend/app/services/data_collection.py

from datetime import datetime
import json
import logging

logger = logging.getLogger(__name__)

class TrainingDataCollector:
    """
    收集和标注训练数据
    """
    
    def __init__(self, db_session, redis_client):
        self.db = db_session
        self.redis = redis_client
    
    async def collect_decision_data(
        self,
        decision_id: str,
        market_data: dict,
        ai_decision: dict,
        account_state: dict
    ):
        """
        实时收集决策数据
        """
        data_point = {
            "conversation_id": decision_id,
            "timestamp": datetime.now().isoformat(),
            "input": {
                "market_data": market_data,
                "account_state": account_state,
                "recent_history": await self._get_recent_history(3)
            },
            "output": ai_decision,
            "result": None,  # 待填充
            "label": "pending"  # 待标注
        }
        
        # 保存到数据库
        await self.db.execute(
            """
            INSERT INTO training_data (decision_id, data, status)
            VALUES (:id, :data, 'pending')
            """,
            {"id": decision_id, "data": json.dumps(data_point)}
        )
        await self.db.commit()
        
        logger.info(f"📝 训练数据已收集: {decision_id}")
    
    async def label_completed_decision(
        self,
        decision_id: str,
        result: dict
    ):
        """
        决策完成后标注（交易关闭后）
        """
        # 1. 获取数据点
        row = await self.db.execute(
            "SELECT * FROM training_data WHERE decision_id = :id",
            {"id": decision_id}
        )
        data_point = json.loads(row["data"])
        
        # 2. 添加结果
        data_point["result"] = result
        
        # 3. 自动标注
        label = self._auto_label(data_point)
        data_point["label"] = label
        
        # 4. 更新数据库
        await self.db.execute(
            """
            UPDATE training_data
            SET data = :data, status = 'labeled', label = :label
            WHERE decision_id = :id
            """,
            {
                "id": decision_id,
                "data": json.dumps(data_point),
                "label": label
            }
        )
        await self.db.commit()
        
        logger.info(f"✅ 数据标注完成: {decision_id} → {label}")
    
    def _auto_label(self, data_point: dict) -> str:
        """
        自动标注决策质量
        
        规则：
        - excellent_decision: 盈利 > 5%
        - good_decision: 盈利 0-5%
        - acceptable_loss: 亏损 < 3% (止损正常)
        - bad_decision: 亏损 > 3%
        """
        result = data_point["result"]
        size_usd = data_point["output"]["size_usd"]
        
        if result["profitable"] and result["pnl"] > 0:
            # 盈利交易
            profit_pct = result["pnl"] / size_usd
            if profit_pct > 0.05:
                return "excellent_decision"  # 盈利>5%
            else:
                return "good_decision"  # 小幅盈利
        
        elif not result["profitable"]:
            # 亏损交易
            loss_pct = abs(result["pnl"]) / size_usd
            if loss_pct > 0.03:
                return "bad_decision"  # 亏损>3%
            else:
                return "acceptable_loss"  # 小幅亏损（止损正常）
        
        else:
            return "neutral"
    
    async def export_training_dataset(
        self,
        output_file: str,
        min_samples: int = 1000
    ):
        """
        导出训练数据集
        """
        # 获取所有已标注数据
        rows = await self.db.execute(
            """
            SELECT * FROM training_data
            WHERE status = 'labeled'
              AND label IN ('excellent_decision', 'good_decision', 'bad_decision')
            ORDER BY created_at DESC
            LIMIT :limit
            """,
            {"limit": min_samples * 2}
        )
        
        dataset = []
        label_counts = {"excellent": 0, "good": 0, "bad": 0}
        
        for row in rows:
            data_point = json.loads(row["data"])
            dataset.append(data_point)
            
            # 统计
            if data_point["label"] == "excellent_decision":
                label_counts["excellent"] += 1
            elif data_point["label"] == "good_decision":
                label_counts["good"] += 1
            elif data_point["label"] == "bad_decision":
                label_counts["bad"] += 1
        
        # 保存为JSONL格式
        with open(output_file, "w") as f:
            for data in dataset:
                f.write(json.dumps(data, ensure_ascii=False) + "\n")
        
        logger.info(f"📊 训练数据导出: {len(dataset)}条 → {output_file}")
        logger.info(f"   - 优秀决策: {label_counts['excellent']}")
        logger.info(f"   - 良好决策: {label_counts['good']}")
        logger.info(f"   - 失败决策: {label_counts['bad']}")
        
        return {
            "total_samples": len(dataset),
            "excellent": label_counts["excellent"],
            "good": label_counts["good"],
            "bad": label_counts["bad"]
        }
    
    async def _get_recent_history(self, limit: int = 3) -> list:
        """获取最近的历史决策"""
        # 从Redis获取
        # 实现省略...
        return []
```

---

## 🎓 模型训练流程

### LoRA微调方案

**为什么使用LoRA**:
- ✅ 只训练少量参数（<1%）
- ✅ 显存占用低（7B模型仅需12GB）
- ✅ 训练速度快
- ✅ 可以保留多个LoRA适配器

```python
# train_model.py

from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)
from peft import LoraConfig, get_peft_model, TaskType
from datasets import load_dataset

def prepare_dataset(data_file: str, tokenizer):
    """
    准备训练数据
    """
    dataset = load_dataset("json", data_files=data_file, split="train")
    
    def format_prompt(example):
        """
        将数据转换为训练格式
        """
        input_data = example['input']
        output_data = example['output']
        
        # 构建Prompt
        prompt = f"""你是专业的加密货币量化交易AI。

市场状态：
{json.dumps(input_data['market_data'], indent=2, ensure_ascii=False)}

账户状态：
余额: ${input_data['account_state']['balance']:.2f}
权限等级: {input_data['account_state']['permission_level']}

请做出交易决策（JSON格式）：
"""
        
        # 构建Response
        response = json.dumps(output_data, ensure_ascii=False, indent=2)
        
        # 组合
        full_text = prompt + response
        
        return {"text": full_text}
    
    # 应用格式化
    dataset = dataset.map(format_prompt, remove_columns=dataset.column_names)
    
    # Tokenize
    def tokenize_function(examples):
        return tokenizer(
            examples["text"],
            truncation=True,
            max_length=2048,
            padding="max_length"
        )
    
    tokenized_dataset = dataset.map(
        tokenize_function,
        batched=True,
        remove_columns=["text"]
    )
    
    return tokenized_dataset

def train_lora_model(
    base_model_name: str,
    data_file: str,
    output_dir: str
):
    """
    使用LoRA微调模型
    """
    # 1. 加载基础模型
    print("📥 加载基础模型...")
    tokenizer = AutoTokenizer.from_pretrained(base_model_name)
    model = AutoModelForCausalLM.from_pretrained(
        base_model_name,
        torch_dtype=torch.float16,
        device_map="auto"
    )
    
    # 2. 配置LoRA
    print("⚙️ 配置LoRA...")
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=16,  # LoRA rank
        lora_alpha=32,
        lora_dropout=0.1,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],  # 应用到attention层
        bias="none"
    )
    
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    
    # 3. 准备数据
    print("📊 准备训练数据...")
    train_dataset = prepare_dataset(data_file, tokenizer)
    
    # 4. 训练配置
    training_args = TrainingArguments(
        output_dir=output_dir,
        per_device_train_batch_size=4,
        gradient_accumulation_steps=4,
        num_train_epochs=3,
        learning_rate=2e-4,
        fp16=True,
        logging_steps=10,
        save_steps=100,
        evaluation_strategy="steps",
        eval_steps=100,
        warmup_steps=50,
        report_to="tensorboard"
    )
    
    # 5. 创建Trainer
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)
    )
    
    # 6. 开始训练
    print("🚀 开始训练...")
    trainer.train()
    
    # 7. 保存模型
    print("💾 保存模型...")
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    
    print("✅ 训练完成！")

# 使用示例
if __name__ == "__main__":
    train_lora_model(
        base_model_name="deepseek-ai/deepseek-coder-7b-instruct-v1.5",
        data_file="./data/training_data.jsonl",
        output_dir="./models/ai_trader_v1"
    )
```

---

## 🧪 A/B测试框架

### 模型并行运行

```python
# backend/app/services/model_ab_testing.py

class ModelABTestingService:
    """
    A/B测试服务：并行运行API模型和自建模型
    """
    
    def __init__(self):
        self.deepseek_api = DeepSeekDecisionEngine()  # API模型
        self.custom_model = CustomModelInference()     # 自建模型
        self.db = get_db_session()
    
    async def make_decision_with_ab_test(
        self,
        market_data: dict,
        account_state: dict,
        test_ratio: float = 0.5  # 50%流量给自建模型
    ) -> dict:
        """
        A/B测试决策
        
        Args:
            market_data: 市场数据
            account_state: 账户状态
            test_ratio: 自建模型流量占比
            
        Returns:
            决策结果
        """
        import random
        
        # 随机分配流量
        use_custom_model = random.random() < test_ratio
        
        if use_custom_model:
            # 使用自建模型
            decision = await self.custom_model.predict(market_data, account_state)
            model_used = "custom_model"
        else:
            # 使用API模型
            decision = await self.deepseek_api.analyze_market_data(market_data)
            model_used = "deepseek_api"
        
        # 记录使用的模型
        decision["_model_used"] = model_used
        
        # 保存到数据库（用于后续比较）
        await self._log_ab_test_decision(decision, model_used)
        
        logger.info(f"✅ A/B测试决策: {model_used}")
        
        return decision
    
    async def get_ab_test_performance(
        self,
        days: int = 7
    ) -> dict:
        """
        获取A/B测试性能对比
        """
        since = datetime.now() - timedelta(days=days)
        
        # 获取两个模型的交易记录
        api_results = await self.db.execute(
            """
            SELECT * FROM trades
            WHERE model_used = 'deepseek_api'
              AND created_at > :since
              AND status = 'closed'
            """,
            {"since": since}
        )
        
        custom_results = await self.db.execute(
            """
            SELECT * FROM trades
            WHERE model_used = 'custom_model'
              AND created_at > :since
              AND status = 'closed'
            """,
            {"since": since}
        )
        
        # 计算性能指标
        api_metrics = self._calculate_metrics(api_results)
        custom_metrics = self._calculate_metrics(custom_results)
        
        return {
            "api_model": api_metrics,
            "custom_model": custom_metrics,
            "comparison": {
                "win_rate_diff": custom_metrics["win_rate"] - api_metrics["win_rate"],
                "pnl_diff": custom_metrics["total_pnl"] - api_metrics["total_pnl"],
                "sharpe_diff": custom_metrics["sharpe_ratio"] - api_metrics["sharpe_ratio"]
            }
        }
    
    def _calculate_metrics(self, trades: list) -> dict:
        """计算性能指标"""
        if not trades:
            return {
                "total_trades": 0,
                "win_rate": 0,
                "total_pnl": 0,
                "sharpe_ratio": 0
            }
        
        total = len(trades)
        winning = sum(1 for t in trades if t["pnl"] > 0)
        pnls = [t["pnl"] for t in trades]
        
        return {
            "total_trades": total,
            "win_rate": winning / total,
            "total_pnl": sum(pnls),
            "avg_pnl": statistics.mean(pnls),
            "sharpe_ratio": (
                statistics.mean(pnls) / statistics.stdev(pnls) * math.sqrt(252)
                if len(pnls) > 1 and statistics.stdev(pnls) > 0
                else 0
            )
        }
```

---

## 🔄 持续优化机制

### 每周重训练

```python
# backend/app/tasks/model_training.py

from celery import Celery

celery = Celery("ai_trading")

@celery.task
async def weekly_model_retrain():
    """
    每周重新训练模型
    触发时间: 每周日 02:00 UTC
    """
    logger.info("🚀 开始每周模型重训练...")
    
    # 1. 导出最新训练数据
    collector = TrainingDataCollector(db, redis)
    stats = await collector.export_training_dataset(
        output_file="./data/training_data_latest.jsonl",
        min_samples=1000
    )
    
    if stats["total_samples"] < 500:
        logger.warning("⚠️ 训练数据不足500条，跳过本周训练")
        return
    
    # 2. 触发训练任务（在PAI平台）
    # 可以通过API调用阿里云PAI训练作业
    # 或者手动执行训练脚本
    
    logger.info("✅ 训练数据准备完成，等待手动触发训练")
```

---

## 💰 成本分析

### 月度成本预估

| 项目 | Phase 1-2 (API) | Phase 3 (API+自建) | Phase 4 (纯自建) |
|------|----------------|-------------------|-----------------|
| **DeepSeek API** | ¥300-500 | ¥150-250 | ¥0 |
| **阿里云GPU** | ¥0 | ¥10,800 | ¥7,200(包月) |
| **存储&带宽** | ¥50 | ¥100 | ¥100 |
| **总计** | ¥350-550 | ¥11,050-11,150 | ¥7,300 |

### 成本拐点分析

```
如果每月API调用成本 > ¥7,200
则自建模型更划算

预估API调用量：
- 每小时1次决策 × 24小时 × 30天 = 720次/月
- DeepSeek成本约¥0.5/次（含Prompt+Response）
- 月成本 = 720 × 0.5 = ¥360

结论：
Phase 1-2 使用API更划算（成本低、快速验证）
Phase 3+ 如果交易频率提高，自建模型开始显现优势
```

---

## ✅ Phase 3 实施检查清单

### 数据准备阶段
- [ ] Phase 1-2 收集至少1000条已标注决策数据
- [ ] 数据质量检查（标注准确率>90%）
- [ ] 数据平衡检查（good/bad比例合理）

### 模型训练阶段
- [ ] 开通阿里云PAI服务
- [ ] 下载基础模型（DeepSeek 7B或类似）
- [ ] 完成LoRA微调训练
- [ ] 模型评估（准确率、推理速度）

### A/B测试阶段
- [ ] 部署自建模型到推理服务
- [ ] 实现A/B测试框架
- [ ] 设置50%流量给自建模型
- [ ] 运行至少2周收集对比数据

### 上线切换阶段
- [ ] 自建模型性能 ≥ API模型
- [ ] 稳定性测试通过（7天无故障）
- [ ] 成本效益分析通过
- [ ] 逐步提高自建模型流量到100%

---

**文档状态**: ✅ 完成  
**适用阶段**: Phase 3（模型自建）  
**前置依赖**: Phase 1-2 数据积累  
**最后更新**: 2025-10-31

---

*本文档提供Phase 3自建模型的完整方案。实施前请确保Phase 1-2已稳定运行并积累足够数据。*

