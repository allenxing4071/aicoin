# AIæˆæœ¬æ•°æ®è·å–è¯´æ˜

## ğŸ“Š æ•°æ®æ¥æº

AIæˆæœ¬ç®¡ç†é¡µé¢æ˜¾ç¤ºçš„æ•°æ®**å®Œå…¨æ¥è‡ªå„AIå¹³å°çš„å®é™…APIè°ƒç”¨**,ä¸æ˜¯æ‰‹åŠ¨å½•å…¥çš„ã€‚

## ğŸ”„ æ•°æ®æµç¨‹

### 1. APIè°ƒç”¨æ—¶è‡ªåŠ¨è®°å½•

æ¯æ¬¡è°ƒç”¨AIå¹³å°APIæ—¶,ç³»ç»Ÿä¼šè‡ªåŠ¨è®°å½•:

```python
# åœ¨ QwenSearchAdapter.analyze() ä¸­
response = await self.client.chat.completions.create(...)

# è·å–tokenä½¿ç”¨æƒ…å†µ
usage = response.usage
cost = self._calculate_cost(
    usage.prompt_tokens,
    usage.completion_tokens
)

# è®°å½•è°ƒç”¨ç»Ÿè®¡
await self._record_call(success=True, cost=cost)
```

### 2. æˆæœ¬è®¡ç®—

æ ¹æ®å„å¹³å°çš„å®šä»·è‡ªåŠ¨è®¡ç®—:

```python
def _calculate_cost(self, prompt_tokens: int, completion_tokens: int) -> float:
    """
    è®¡ç®—APIè°ƒç”¨æˆæœ¬
    
    Qwenå®šä»·ï¼ˆç¤ºä¾‹ï¼‰ï¼š
    - Input: Â¥4.0 / 1M tokens
    - Output: Â¥12.0 / 1M tokens
    """
    input_cost = (prompt_tokens / 1_000_000) * 4.0
    output_cost = (completion_tokens / 1_000_000) * 12.0
    return input_cost + output_cost
```

### 3. æ•°æ®åº“æ›´æ–°

ç»Ÿè®¡æ•°æ®å®æ—¶æ›´æ–°åˆ°æ•°æ®åº“:

```python
async def update_platform_stats(
    self,
    provider: str,
    success: bool,
    response_time: float,
    cost: float = 0.0
):
    """æ›´æ–°å¹³å°ç»Ÿè®¡ä¿¡æ¯"""
    platform.total_calls += 1
    if success:
        platform.successful_calls += 1
    else:
        platform.failed_calls += 1
    
    # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
    platform.avg_response_time = (
        platform.avg_response_time * 0.9 + response_time * 0.1
    )
    
    platform.total_cost += cost
    await db.commit()
```

## ğŸ“ˆ å®é™…æ•°æ®ç¤ºä¾‹

ä»åˆšæ‰çš„æ¨¡æ‹Ÿæ•°æ®å¯ä»¥çœ‹åˆ°:

| å¹³å° | è°ƒç”¨æ¬¡æ•° | æˆåŠŸç‡ | æˆæœ¬ | å“åº”æ—¶é—´ |
|------|---------|--------|------|---------|
| DeepSeek Chat | 100 | 93.6% | Â¥0.3368 | 1392ms |
| è…¾è®¯äº‘ (Qwenæœç´¢) | 42 | 93.0% | Â¥0.7849 | 1968ms |
| ç«å±±å¼•æ“ (Qwenæœç´¢) | 38 | 95.0% | Â¥0.8890 | 1562ms |
| ç™¾åº¦æ™ºèƒ½äº‘ (Qwenæœç´¢) | 24 | 92.9% | Â¥0.5833 | 1553ms |
| Qwen-Plus | 41 | 93.5% | Â¥1.0585 | 1464ms |

**æ€»è®¡**: 245æ¬¡è°ƒç”¨, Â¥3.6525, å¹³å‡æˆåŠŸç‡93.06%

## ğŸ”§ æ•°æ®è·å–æ–¹å¼

### æ–¹å¼1: å®é™…è¿è¡Œç³»ç»Ÿ

å½“ç³»ç»Ÿå®é™…è¿è¡Œæ—¶,æ¯æ¬¡AIå†³ç­–æˆ–æƒ…æŠ¥æ”¶é›†éƒ½ä¼šè‡ªåŠ¨äº§ç”Ÿæ•°æ®:

```python
# åœ¨ AITradingOrchestratorV2 ä¸­
async def make_decision(self, symbol: str):
    # 1. æ”¶é›†æƒ…æŠ¥ (è°ƒç”¨Qwenç³»åˆ—API)
    intelligence = await self.intelligence_engine.gather_intelligence(symbol)
    
    # 2. åšå‡ºå†³ç­– (è°ƒç”¨DeepSeek API)
    decision = await self.decision_maker.make_decision(intelligence)
    
    # æ¯æ¬¡è°ƒç”¨éƒ½ä¼šè‡ªåŠ¨è®°å½•tokenä½¿ç”¨å’Œæˆæœ¬
```

### æ–¹å¼2: ä½¿ç”¨æ¨¡æ‹Ÿè„šæœ¬

å¯¹äºæ¼”ç¤ºå’Œæµ‹è¯•,å¯ä»¥ä½¿ç”¨æ¨¡æ‹Ÿè„šæœ¬ç”Ÿæˆæ•°æ®:

```bash
# ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
docker exec aicoin-backend python scripts/simulate_ai_usage.py

# é‡ç½®æ•°æ®ä¸º0
docker exec aicoin-backend python scripts/simulate_ai_usage.py --reset
```

## ğŸ’¡ å…³é”®ç‰¹æ€§

### 1. è‡ªåŠ¨è¿½è¸ª

âœ… **æ— éœ€æ‰‹åŠ¨è®°å½•** - æ¯æ¬¡APIè°ƒç”¨è‡ªåŠ¨è®°å½•  
âœ… **ç²¾ç¡®è®¡ç®—** - åŸºäºå®é™…tokenä½¿ç”¨é‡è®¡ç®—æˆæœ¬  
âœ… **å®æ—¶æ›´æ–°** - æ•°æ®ç«‹å³å†™å…¥æ•°æ®åº“  

### 2. å¤šç»´åº¦ç»Ÿè®¡

- **è°ƒç”¨æ¬¡æ•°**: æ€»è°ƒç”¨ã€æˆåŠŸã€å¤±è´¥
- **æˆæœ¬ç»Ÿè®¡**: æ€»æˆæœ¬ã€æœˆæˆæœ¬ã€æ—¥æˆæœ¬
- **æ€§èƒ½æŒ‡æ ‡**: å“åº”æ—¶é—´ã€æˆåŠŸç‡
- **å¥åº·çŠ¶æ€**: æœ€åæ£€æŸ¥æ—¶é—´ã€å¥åº·çŠ¶æ€

### 3. æˆæœ¬ä¼˜åŒ–

ç³»ç»Ÿä¼šæ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µæä¾›ä¼˜åŒ–å»ºè®®:

```python
# å†³ç­–é—´éš”ä¼˜åŒ–
current_interval = 60  # 60ç§’
if total_cost > budget_threshold:
    recommended_interval = 120  # å»ºè®®å»¶é•¿åˆ°120ç§’
    estimated_savings = calculate_savings(current_interval, recommended_interval)
```

## ğŸ“Š å‰ç«¯æ•°æ®å±•ç¤º

### APIç«¯ç‚¹

```
GET /api/v1/intelligence/platforms
```

è¿”å›æ•°æ®æ ¼å¼:

```json
{
  "platforms": [
    {
      "id": 7,
      "name": "è…¾è®¯äº‘ (Qwenæœç´¢)",
      "provider": "tencent",
      "platform_type": "intelligence",
      "enabled": true,
      "performance": {
        "total_calls": 42,
        "successful_calls": 39,
        "failed_calls": 3,
        "success_rate": 0.9286,
        "total_cost": 0.7849,
        "avg_response_time": 1968.11
      },
      "health": {
        "last_check": "2025-11-09T03:30:23.849882",
        "status": "healthy"
      }
    }
  ],
  "total": 5
}
```

### å‰ç«¯å±•ç¤º

```typescript
// è·å–å¹³å°æ•°æ®
const res = await fetch('http://localhost:8000/api/v1/intelligence/platforms');
const data = await res.json();

// è®¡ç®—æ€»æˆæœ¬
const totalCost = data.platforms.reduce(
  (sum, p) => sum + p.performance.total_cost, 
  0
);

// æ˜¾ç¤ºåœ¨é¡µé¢ä¸Š
<div>æ€»æˆæœ¬: Â¥{totalCost.toFixed(2)}</div>
```

## ğŸ¯ å®šä»·é…ç½®

å„å¹³å°å®šä»·åœ¨ä»£ç ä¸­é…ç½®:

```python
# backend/app/services/ai_cost_manager.py
MODEL_PRICING = {
    "deepseek-chat": {
        "input_price": 1.0,   # Â¥1.0/ç™¾ä¸‡tokens
        "output_price": 2.0,  # Â¥2.0/ç™¾ä¸‡tokens
    },
    "qwen-plus": {
        "input_price": 4.0,   # Â¥4.0/ç™¾ä¸‡tokens
        "output_price": 12.0, # Â¥12.0/ç™¾ä¸‡tokens
    },
    # ... å…¶ä»–æ¨¡å‹
}
```

ä¹Ÿå¯ä»¥åœ¨æ•°æ®åº“ä¸­é…ç½®:

```sql
UPDATE intelligence_platforms 
SET config_json = jsonb_set(
    config_json, 
    '{input_price_per_million}', 
    '4.0'
)
WHERE provider = 'qwen';
```

## ğŸ” API Keyç®¡ç†

API Keyå®‰å…¨å­˜å‚¨åœ¨æ•°æ®åº“ä¸­:

```python
# åŠ å¯†å­˜å‚¨
platform.api_key = encrypt(api_key)

# ä½¿ç”¨æ—¶è§£å¯†
api_key = decrypt(platform.api_key)
client = OpenAI(api_key=api_key, base_url=platform.base_url)
```

## ğŸ“ ä½¿ç”¨æ—¥å¿—

è¯¦ç»†çš„ä½¿ç”¨æ—¥å¿—å­˜å‚¨åœ¨ `ai_model_usage_log` è¡¨ä¸­:

```sql
SELECT 
    model_name,
    input_tokens,
    output_tokens,
    cost,
    response_time,
    created_at
FROM ai_model_usage_log
ORDER BY created_at DESC
LIMIT 10;
```

## ğŸ‰ æ€»ç»“

AIæˆæœ¬æ•°æ®**å®Œå…¨æ¥è‡ªå®é™…APIè°ƒç”¨**,ç³»ç»Ÿè‡ªåŠ¨:
1. âœ… è®°å½•æ¯æ¬¡è°ƒç”¨çš„tokenä½¿ç”¨
2. âœ… æ ¹æ®å®šä»·è®¡ç®—æˆæœ¬
3. âœ… æ›´æ–°ç»Ÿè®¡æ•°æ®åˆ°æ•°æ®åº“
4. âœ… åœ¨å‰ç«¯å®æ—¶å±•ç¤º

**æ— éœ€æ‰‹åŠ¨å½•å…¥,æ•°æ®100%çœŸå®å¯é !** ğŸš€

